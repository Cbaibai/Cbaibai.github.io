

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=&#34;auto&#34;>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/favicon.png">
  <link rel="icon" type="image/png" href="/img/favicon.png">
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="description" content="本站所有文章系原创，如有文章侵权请联系2583245026@qq.com，我会及时删除！">
  <meta name="author" content="Cbaibai">
  <meta name="keywords" content="">
  <title>OpenCV中的图像处理 - 摆摆笔记</title>

  <link  rel="stylesheet" href="https://cdn.staticfile.org/twitter-bootstrap/4.5.3/css/bootstrap.min.css" />


  <link  rel="stylesheet" href="https://cdn.staticfile.org/github-markdown-css/4.0.0/github-markdown.min.css" />
  <link  rel="stylesheet" href="/lib/hint/hint.min.css" />

  
    
    
      
      <link  rel="stylesheet" href="https://cdn.staticfile.org/highlight.js/10.1.2/styles/github-gist.min.css" />
    
  

  
    <link  rel="stylesheet" href="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.css" />
  



<!-- 主题依赖的图标库，不要自行修改 -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_ba1fz6golrf.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_kmeydafke9r.css">


<link  rel="stylesheet" href="/css/main.css" />

<!-- 自定义样式保持在最底部 -->


  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    var CONFIG = {"hostname":"baibainote.pro","root":"/","version":"1.8.5","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false},"toc":{"enable":true,"headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"right","visible":"hover","icon":""},"copy_btn":true,"image_zoom":{"enable":true},"lazyload":{"enable":true,"onlypost":false},"web_analytics":{"enable":false,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null}}};
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
<meta name="generator" content="Hexo 5.0.2"></head>


<body>
  <header style="height: 70vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand"
       href="/">&nbsp;<strong>Fluid</strong>&nbsp;</a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                归档
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                分类
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                标签
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" data-toggle="modal" data-target="#modalSearch">&nbsp;<i
                class="iconfont icon-search"></i>&nbsp;</a>
          </li>
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" href="javascript:">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div class="banner intro-2" id="background" parallax=true
         style="background: url('/img/default.png') no-repeat center center;
           background-size: cover;">
      <div class="full-bg-img">
        <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
          <div class="page-header text-center fade-in-up">
            <span class="h2" id="subtitle" title="OpenCV中的图像处理">
              
            </span>

            
              <div class="mt-3">
  
  
    <span class="post-meta">
      <i class="iconfont icon-date-fill" aria-hidden="true"></i>
      <time datetime="2020-03-15 15:35" pubdate>
        2020年3月15日 下午
      </time>
    </span>
  
</div>

<div class="mt-1">
  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-chart"></i>
      0 字
    </span>
  

  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-clock-fill"></i>
      
      
      1
       分钟
    </span>
  

  
  
</div>

            
          </div>

          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid">
  <div class="row">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-md">
      <div class="container nopadding-md" id="board-ctn">
        <div class="py-5" id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">OpenCV中的图像处理</h1>
            
            <div class="markdown-body">
              <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/lightgallery.js/1.0.1/css/lightgallery.min.css" /><div class=".article-gallery"<h1 id="颜色空间转换"><a href="#颜色空间转换" class="headerlink" title="颜色空间转换"></a>颜色空间转换</h1><h2 id="转换颜色空间"><a href="#转换颜色空间" class="headerlink" title="转换颜色空间"></a>转换颜色空间</h2><p>&emsp;&emsp;OpenCV提供了超过150 种进行颜色空间转换的方法，但是以后经常用到的其实也就两种：BGR&rarr;Gray 和BGR&rarr;HSV。进行颜色空间转换的函数是：<code>cv2.cvtColor(input_image，flag)</code>，其中flag就是要转换到的类型。</p>
<p>&emsp;&emsp;对于BGR&rarr;Gray 的转换，我们要使用的flag 就是cv2.COLOR_ BGR2GRAY。而对于BGR&rarr;HSV 的转换，我们用的flag 就是cv2.COLOR_BGR2HSV。</p>
<p>可以使用下面的程序输出opencv中支持的所有用于颜色空间转换的flag：<br>&lt;!–hexoPostRenderEscape:<pre><code class="hljs python"><span class="hljs-keyword">import</span> cv2</p>
<p>flags=[i <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">dir</span>(cv2) <span class="hljs-keyword">if</span> i.startswith(<span class="hljs-string">&#x27;COLOR_&#x27;</span>)]<br>print(flags)</code></pre>:hexoPostRenderEscape–&gt;<br><a href="WEBRESOURCE0e328e78ef5da029363c35b38d0fc051" title="image.png" class="gallery-item"><img src="WEBRESOURCE0e328e78ef5da029363c35b38d0fc051" srcset="/img/loading.gif" alt="image.png"></a></p>
<div style="border: 1px solid #ddd;padding:2px;"><br><div style="background-color:#609090;color:white;text-align:center;padding:5px;border-radius:5px;">注意</div>

<p>&emsp;&emsp;在OpenCV 的HSV 格式中，H（色彩/色度）的取值范围是[0，179]，S（饱和度）的取值范围[0，255]，V（亮度）的取值范围[0，255]。但是不同软件使用的值可能不同，所以当你需要拿OpenCV 的HSV 值与其他软<br>件的HSV 值进行对比时，一定要记得归一化处理。<br></div><br></p>
<h2 id="物体跟踪"><a href="#物体跟踪" class="headerlink" title="物体跟踪"></a>物体跟踪</h2><p>&emsp;&emsp;我们已经知道怎样将一幅图像从BGR颜色空间转换到HSV了，这样一来，我们就可以利用这一点来提取带有某个特定颜色的物体。在HSV颜色空间中要比在BGR空间中更容易表示一个特定颜色。</p>
<p>在接下来的例子中我们要提取一个蓝色的物体，做下面几步操作：</p>
<ul>
<li>从视频中获取每一帧图像；</li>
<li>将图像转换到HSV 空间；</li>
<li>设置HSV 阈值到蓝色范围。</li>
</ul>
<pre><code class="hljs python"><span class="hljs-keyword">import</span> cv2
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np

cap=cv2.VideoCapture(<span class="hljs-number">0</span>)
<span class="hljs-keyword">while</span>(<span class="hljs-number">1</span>):
    <span class="hljs-comment"># 获取捕获到的每一帧</span>
    ret,frame=cap.read()

    <span class="hljs-comment"># 转换到HSV颜色空间</span>
    hsv_img=cv2.cvtColor(frame,cv2.COLOR_BGR2HSV)

    <span class="hljs-comment"># 设定蓝色的阈值(颜色值达到什么样才判断为蓝色)</span>
    lower_blue=np.array([<span class="hljs-number">110</span>,<span class="hljs-number">50</span>,<span class="hljs-number">50</span>])
    upper_blue=np.array([<span class="hljs-number">130</span>,<span class="hljs-number">255</span>,<span class="hljs-number">255</span>])

    <span class="hljs-comment"># 根据阈值构建掩模(低于lower_blue为黑色，高于upper_blue的为白色)</span>
    mask=cv2.inRange(hsv_img,lower_blue,upper_blue)

    <span class="hljs-comment"># 对原图像和掩模进行按位与运算</span>
    res=cv2.bitwise_and(frame,frame,mask=mask)

    <span class="hljs-comment"># 显示图像</span>
    cv2.imshow(<span class="hljs-string">&#x27;frame&#x27;</span>,frame)
    cv2.imshow(<span class="hljs-string">&#x27;mask&#x27;</span>,mask)
    cv2.imshow(<span class="hljs-string">&#x27;res&#x27;</span>,res)
    k=cv2.waitKey(<span class="hljs-number">5</span>)
    <span class="hljs-keyword">if</span> k==<span class="hljs-number">27</span>:
        <span class="hljs-keyword">break</span>

<span class="hljs-comment"># 关闭窗口</span>
cv2.destroyAllWindows()</code></pre>
<p><a href="WEBRESOURCE90bdfb92a45299da1b8d8eeae88459d6" title="image.png" class="gallery-item"><img src="WEBRESOURCE90bdfb92a45299da1b8d8eeae88459d6" srcset="/img/loading.gif" alt="image.png"></a></p>
<p>上图掩膜中一些白色的点就是图像处理中的噪点。</p>
<h2 id="找到跟踪对象的HSV-值"><a href="#找到跟踪对象的HSV-值" class="headerlink" title="找到跟踪对象的HSV 值"></a>找到跟踪对象的HSV 值</h2><pre><code class="hljs python"><span class="hljs-keyword">import</span> cv2
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np

<span class="hljs-comment"># 不能用[0,255,0]，而要用[[[0,255,0]]]</span>
<span class="hljs-comment"># 这里的三层括号应该分别对应于cvArray，cvMat，IplImage</span>
green=np.uint8([[[<span class="hljs-number">0</span>,<span class="hljs-number">255</span>,<span class="hljs-number">0</span>]]])
hsv_green=cv2.cvtColor(green,cv2.COLOR_BGR2HSV)    <span class="hljs-comment"># 绿色的HSV值</span>
print(hsv_green)</code></pre>
<p><a href="WEBRESOURCEf817a41fc9fb30078ced4506854a3886" title="image.png" class="gallery-item"><img src="WEBRESOURCEf817a41fc9fb30078ced4506854a3886" srcset="/img/loading.gif" alt="image.png"></a></p>
<p>可见，BGR颜色空间中的绿色对应HSV的[60,255,255]。</p>
<h1 id="几何变换"><a href="#几何变换" class="headerlink" title="几何变换"></a>几何变换</h1><p>&emsp;&emsp;OpenCV 提供了两个变换函数，<code>cv2.warpAffine</code>和<code>cv2.warpPerspective</code>，使用这两个函数你可以实现所有类型的变换。cv2.warpAffine 接收的参数是2 <em> 3的变换矩阵，而cv2.warpPerspective 接收的参数是3 </em> 3 的变换矩阵。</p>
<h2 id="缩放"><a href="#缩放" class="headerlink" title="缩放"></a>缩放</h2><p>&emsp;&emsp;扩展缩放只是改变图像的尺寸大小。OpenCV提供的函数<code>cv2,resize(src, dst, interpolation=CV_INTER_LINEAR)</code>可以实现这个功能，图像的尺寸可以自己手动设置，也可以指定缩放因子。我们可以选择使用不同的插值方法，在缩放时我们推荐使用cv2.INTER_ AREA，在扩展时我们推荐使用v2.INTER_ CUBIC（慢)和v2.INTER_ LINEAR。默认情况下所有改变图像尺寸大小的操作使用的插值方法都是cv2.INTER_LINEAR。</p>
<pre><code class="hljs python"><span class="hljs-keyword">import</span> cv2
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np

img=cv2.imread(<span class="hljs-string">&#x27;miss.jpg&#x27;</span>)
<span class="hljs-comment"># 下面的None所占的参数位置本应该是输出图像的尺寸，但是因为后边我们设置了缩放因子(fx,fy),因此这里直接写None就好</span>
res=cv2.resize(img,<span class="hljs-literal">None</span>,fx=<span class="hljs-number">2</span>,fy=<span class="hljs-number">2</span>,interpolation=cv2.INTER_CUBIC)

<span class="hljs-comment"># 这里呢，我们直接设置输出图像的尺寸，所以不用设置缩放因子</span>
height,width=img.shape[:<span class="hljs-number">2</span>]    <span class="hljs-comment"># 得到原图像的宽高</span>
res=cv2.resize(img,(<span class="hljs-number">2</span>*width,<span class="hljs-number">2</span>*height),interpolation=cv2.INTER_CUBIC)    <span class="hljs-comment"># 对原图像放大两倍</span>

<span class="hljs-keyword">while</span>(<span class="hljs-number">1</span>):
    cv2.imshow(<span class="hljs-string">&#x27;res&#x27;</span>,res)
    cv2.imshow(<span class="hljs-string">&#x27;img&#x27;</span>,img)
    <span class="hljs-keyword">if</span> cv2.waitKey(<span class="hljs-number">1</span>) == <span class="hljs-number">27</span>:
        <span class="hljs-keyword">break</span>

cv2.destroyAllWindows()</code></pre>
<p><a href="WEBRESOURCE8f91d7ece88ed49729f06b3eddda03af" title="image.png" class="gallery-item"><img src="WEBRESOURCE8f91d7ece88ed49729f06b3eddda03af" srcset="/img/loading.gif" alt="image.png"></a></p>
<h2 id="平移"><a href="#平移" class="headerlink" title="平移"></a>平移</h2><p>&emsp;&emsp;如果要使图像要沿（x，y）方向移动，移动的距离是（tx，ty），你可以以下面的方式构建移动矩阵：<br><pre><code class="hljs math">M&#x3D;\left[\begin&#123;matrix&#125;
1 &amp; 0 &amp; t_x \\[8pt]
0 &amp; 1 &amp; t_y
\end&#123;matrix&#125;\right]</code></pre><br>可以使用Numpy 数组构建这个矩阵（数据类型是np.float32），然后把它传给函数cv2.warpAffine()即可完成平移。</p>
<h2 id="旋转"><a href="#旋转" class="headerlink" title="旋转"></a>旋转</h2><p>对一个图像绕图片左下角原点旋转θ角, 需要使用到下面形式的旋转矩阵:<br><pre><code class="hljs math">M&#x3D;\left[\begin&#123;matrix&#125;
\cos\theta &amp; -\sin\theta \\[8pt]
\sin\theta &amp; \cos\theta
\end&#123;matrix&#125;\right]</code></pre><br>OpenCV支持绕任意点进行旋转的矩阵：<br><pre><code class="hljs math">M&#x3D;\left[\begin&#123;matrix&#125;
\alpha &amp; \beta &amp; (1-\alpha)\cdot center\cdot x-\beta\cdot center\cdot y \\[8pt]
-\beta &amp; \alpha &amp; \beta\cdot center\cdot x+(1-\alpha)\cdot center\cdot x
\end&#123;matrix&#125;\right]</code></pre><br>其中，<br>&lt;!–hexoPostRenderEscape:<pre><code class="hljs math">\alpha &#x3D; scale\cdot \cos\theta</p>
<p>\beta &#x3D; scale\cdot \sin\theta</code></pre>:hexoPostRenderEscape–&gt;</p>
<p>为了构建这个旋转矩阵，OpenCV 提供了函数：<code>cv2.getRotationMatrix2D()</code>。</p>
<pre><code class="hljs python"><span class="hljs-keyword">import</span> cv2
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np

img=cv2.imread(<span class="hljs-string">&#x27;miss.jpg&#x27;</span>,<span class="hljs-number">0</span>)
rows,cols=img.shape    <span class="hljs-comment"># 得到图像的宽高</span>

<span class="hljs-comment"># (旋转中心，旋转角度，旋转后的缩放因子)</span>
M=cv2.getRotationMatrix2D((cols/<span class="hljs-number">2</span>,rows/<span class="hljs-number">2</span>),<span class="hljs-number">45</span>,<span class="hljs-number">0.6</span>)    <span class="hljs-comment"># 旋转45度</span>

<span class="hljs-comment"># 对图像img施加仿射变换M，第三个参数是输出图像的尺寸中心</span>
dst=cv2.warpAffine(img,M,(<span class="hljs-number">2</span>*cols,<span class="hljs-number">2</span>*rows))

cv2.namedWindow(<span class="hljs-string">&#x27;image&#x27;</span>, cv2.WINDOW_NORMAL)

<span class="hljs-keyword">while</span>(<span class="hljs-number">1</span>):
    cv2.imshow(<span class="hljs-string">&#x27;image&#x27;</span>,dst)
    <span class="hljs-keyword">if</span> cv2.waitKey(<span class="hljs-number">1</span>)==<span class="hljs-number">27</span>:
        <span class="hljs-keyword">break</span>

cv2.destroyAllWindows()</code></pre>
<p><a href="WEBRESOURCEccd2f19140eb7c0cc5758e9c8127789d" title="image.png" class="gallery-item"><img src="WEBRESOURCEccd2f19140eb7c0cc5758e9c8127789d" srcset="/img/loading.gif" alt="image.png"></a></p>
<h2 id="仿射变换"><a href="#仿射变换" class="headerlink" title="仿射变换"></a>仿射变换</h2><p>&emsp;&emsp;在仿射变换中，原图中所有的平行线在结果图像中同样平行(这是一种线性变换)。为了创建这个矩阵，我们需要从原图像中找到三个点以及他们在输出图像中的位置，然后利用<code>cv2.getAffineTransform()</code>创建一个2x3 的矩阵，最后这个矩阵会被传给函数<code>cv2.warpAffine()</code>。</p>
<pre><code class="hljs python"><span class="hljs-keyword">import</span> cv2
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np

img=cv2.imread(<span class="hljs-string">&#x27;miss.jpg&#x27;</span>)
rows,cols,channel=img.shape

<span class="hljs-comment"># 选中原图像上的三个点</span>
before_points=np.float32([[<span class="hljs-number">50</span>,<span class="hljs-number">50</span>],[<span class="hljs-number">200</span>,<span class="hljs-number">50</span>],[<span class="hljs-number">50</span>,<span class="hljs-number">200</span>]])
<span class="hljs-comment"># 定义原图上那三个点在最终目标图片上的位置</span>
after_points=np.float32([[<span class="hljs-number">10</span>,<span class="hljs-number">100</span>],[<span class="hljs-number">200</span>,<span class="hljs-number">50</span>],[<span class="hljs-number">100</span>,<span class="hljs-number">250</span>]])

<span class="hljs-comment"># 基于before_points和after_points生成仿射变换矩阵</span>
M=cv2.getAffineTransform(before_points,after_points)
dst=cv2.warpAffine(img,M,(cols,rows))    <span class="hljs-comment"># 对图像img施加定义好了的仿射变换</span>

cv2.imshow(<span class="hljs-string">&#x27;src&#x27;</span>, img)
cv2.imshow(<span class="hljs-string">&#x27;dst&#x27;</span>, dst)
cv2.waitKey(<span class="hljs-number">0</span>)
cv2.destroyAllWindows()</code></pre>
<p><a href="WEBRESOURCEd03a91969a3a028c2d1e4b6b1784e6ac" title="image.png" class="gallery-item"><img src="WEBRESOURCEd03a91969a3a028c2d1e4b6b1784e6ac" srcset="/img/loading.gif" alt="image.png"></a></p>
<p><a href="WEBRESOURCE618f5289a7f26d3e61233f3ec9f58b3d" title="image.png" class="gallery-item"><img src="WEBRESOURCE618f5289a7f26d3e61233f3ec9f58b3d" srcset="/img/loading.gif" alt="image.png"></a></p>
<h2 id="透视变换"><a href="#透视变换" class="headerlink" title="透视变换"></a>透视变换</h2><p>&emsp;&emsp;对于透视变换，我们需要一个 3x3 的变换矩阵。变换前后直线还是直线。<br><br>&emsp;&emsp;要构建这个变换矩阵，你需要在输入图像上找4个点，并指定它们在输出图像上对应的位置。这四个点中的任意三个都不能共线。这个变换矩阵可以用函数<code>cv2.getPerspectiveTransform()</code>构建。然后把这个矩阵传给函数<code>cv2.warpPerspective()</code>来对源图像进行透视变换。</p>
<pre><code class="hljs python"><span class="hljs-keyword">import</span> cv2
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np

img=cv2.imread(<span class="hljs-string">&#x27;ball.png&#x27;</span>)
rows,cols,ch=img.shape

before_points = np.float32([[<span class="hljs-number">56</span>,<span class="hljs-number">65</span>],[<span class="hljs-number">368</span>,<span class="hljs-number">52</span>],[<span class="hljs-number">28</span>,<span class="hljs-number">387</span>],[<span class="hljs-number">389</span>,<span class="hljs-number">390</span>]])
after_points = np.float32([[<span class="hljs-number">0</span>,<span class="hljs-number">0</span>],[<span class="hljs-number">300</span>,<span class="hljs-number">0</span>],[<span class="hljs-number">0</span>,<span class="hljs-number">300</span>],[<span class="hljs-number">300</span>,<span class="hljs-number">300</span>]])

M=cv2.getPerspectiveTransform(before_points,after_points)
dst=cv2.warpPerspective(img,M,(<span class="hljs-number">300</span>,<span class="hljs-number">300</span>))

cv2.imshow(<span class="hljs-string">&#x27;src&#x27;</span>, img)
cv2.imshow(<span class="hljs-string">&#x27;dst&#x27;</span>, dst)
cv2.waitKey(<span class="hljs-number">0</span>)
cv2.destroyAllWindows()</code></pre>
<p><a href="WEBRESOURCE961f93fa82ae6dc52577d56ed0217d0d" title="image.png" class="gallery-item"><img src="WEBRESOURCE961f93fa82ae6dc52577d56ed0217d0d" srcset="/img/loading.gif" alt="image.png"></a></p>
<h1 id="图像阈值"><a href="#图像阈值" class="headerlink" title="图像阈值"></a>图像阈值</h1><h2 id="简单阈值"><a href="#简单阈值" class="headerlink" title="简单阈值"></a>简单阈值</h2><p>&emsp;&emsp;使用<code>cv2.threshhold()</code>进行简单阈值处理，像素值高于阈值时，我们给这个像素赋予一个新值（可能是白色），否则我们给它赋予另外一种颜色（也许是黑色）。因为这个函数接受的是灰度图，所以像素值其实就是图像的亮度。<br><br>&emsp;&emsp;这个函数的第一个参数就是原图像，<font color=#906060>原图像应该是灰度图(不是灰度图则转换为灰度图)</font>；第二个参数就是用来对像素值进行分类的阈值；第三个参数就是当像素值高于（有时是小于）阈值时应该被赋予的新的像素值。</p>
<p>OpenCV提供了多种不同的阈值方法，这是由第四个参数来决定的。这些方法包括：</p>
<ul>
<li>cv2.THRESH_BINARY</li>
<li>cv2.THRESH_BINARY_INV</li>
<li>cv2.THRESH_TRUNC</li>
<li>cv2.THRESH_TOZERO</li>
<li>cv2.THRESH_TOZERO_INV</li>
</ul>
<p><a href="WEBRESOURCEc6d9383d0a0ca8cfcd1c04b02c6f83ff" title="image.png" class="gallery-item"><img src="WEBRESOURCEc6d9383d0a0ca8cfcd1c04b02c6f83ff" srcset="/img/loading.gif" alt="image.png"></a></p>
<p><code>cv2.threshhold()</code>有两个返回值，第一个为retVal，第二个就是阈值化处理之后的结果图像。</p>
<pre><code class="hljs python"><span class="hljs-keyword">import</span> cv2
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">from</span> matplotlib <span class="hljs-keyword">import</span> pyplot <span class="hljs-keyword">as</span> plt

img=cv2.imread(<span class="hljs-string">&#x27;gradient.png&#x27;</span>,<span class="hljs-number">0</span>)

<span class="hljs-comment"># 对源图像进行各种类型的阈值化处理</span>
ret,thresh1=cv2.threshold(img,<span class="hljs-number">127</span>,<span class="hljs-number">255</span>,cv2.THRESH_BINARY)    <span class="hljs-comment"># 高于127时赋值为255(白色)，低于127时赋值为0(黑色)</span>
ret,thresh2=cv2.threshold(img,<span class="hljs-number">127</span>,<span class="hljs-number">255</span>,cv2.THRESH_BINARY_INV)
ret,thresh3=cv2.threshold(img,<span class="hljs-number">127</span>,<span class="hljs-number">255</span>,cv2.THRESH_TRUNC)
ret,thresh4=cv2.threshold(img,<span class="hljs-number">127</span>,<span class="hljs-number">255</span>,cv2.THRESH_TOZERO)
ret,thresh5=cv2.threshold(img,<span class="hljs-number">127</span>,<span class="hljs-number">255</span>,cv2.THRESH_TOZERO_INV)

titles = [<span class="hljs-string">&#x27;Original Image&#x27;</span>,<span class="hljs-string">&#x27;BINARY&#x27;</span>,<span class="hljs-string">&#x27;BINARY_INV&#x27;</span>,<span class="hljs-string">&#x27;TRUNC&#x27;</span>,<span class="hljs-string">&#x27;TOZERO&#x27;</span>,<span class="hljs-string">&#x27;TOZERO_INV&#x27;</span>]
images = [img, thresh1, thresh2, thresh3, thresh4, thresh5]

<span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">6</span>):
    plt.subplot(<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,i+<span class="hljs-number">1</span>),plt.imshow(images[i],<span class="hljs-string">&#x27;gray&#x27;</span>)
    plt.title(titles[i])
    plt.xticks([]),plt.yticks([])    <span class="hljs-comment"># 隐藏子图的刻度</span>

plt.show()</code></pre>
<p><a href="WEBRESOURCEacd847f77772f568707c528caf2ee05d" title="image.png" class="gallery-item"><img src="WEBRESOURCEacd847f77772f568707c528caf2ee05d" srcset="/img/loading.gif" alt="image.png"></a></p>
<h2 id="自适应阈值"><a href="#自适应阈值" class="headerlink" title="自适应阈值"></a>自适应阈值</h2><p>&emsp;&emsp;前面所说的简单阈值其实是全局阈值，即整幅图像采用同一个数作为阈值。但这种方法显然并不适合于所有情况，尤其是当同一幅图像上的不同部分具有不同亮度时。这种情况下我们就需要采用自适应阈值。<br><br>&emsp;&emsp;此时的阈值是根据图像上的每一个小区域计算与其对应的阈值。因此在同一幅图像上的不同区域采用的实际上是不同的阈值，从而使我们能在图像各部分亮度差异很大的情况下得到更好的结果。</p>
<p>下面的程序展示了简单阈值和自适应阈值的区别：<br>&lt;!–hexoPostRenderEscape:<pre><code class="hljs python"><span class="hljs-keyword">import</span> cv2<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> matplotlib <span class="hljs-keyword">import</span> pyplot <span class="hljs-keyword">as</span> plt</p>
<p>img = cv2.imread(<span class="hljs-string">&#x27;dave.png&#x27;</span>,<span class="hljs-number">0</span>)</p>
<p><span class="hljs-comment"># 中值滤波(除噪点)</span><br>img = cv2.medianBlur(img,<span class="hljs-number">5</span>)<br><span class="hljs-comment"># 这里是简单阈值</span><br>ret,th1 = cv2.threshold(img,<span class="hljs-number">127</span>,<span class="hljs-number">255</span>,cv2.THRESH_BINARY)</p>
<p><span class="hljs-comment"># 使用cv2.adaptiveThreshold()开启自适应阈值，分别使用两种计算阈值的方法：</span><br><span class="hljs-comment"># ADAPTIVE_THRESH_MEAN_C阈值取自相邻区域的平均值 和 </span><br><span class="hljs-comment"># ADAPTIVE_THRESH_GAUSSIAN_C阈值取值相邻区域的加权和，权重为一个高斯窗口</span><br>th2 = cv2.adaptiveThreshold(img,<span class="hljs-number">255</span>,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,<span class="hljs-number">11</span>,<span class="hljs-number">2</span>)<br>th3 = cv2.adaptiveThreshold(img,<span class="hljs-number">255</span>,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,<span class="hljs-number">11</span>,<span class="hljs-number">2</span>)<br><span class="hljs-comment"># 11 为邻域大小Block size(用来计算阈值的区域大小), 2 为C 值(一个常数，阈值就等于的平均值或者加权平均值减去这个常数)</span></p>
<p>titles = [<span class="hljs-string">&#x27;Original Image&#x27;</span>, <span class="hljs-string">&#x27;Global Thresholding (v = 127)&#x27;</span>, <span class="hljs-string">&#x27;Adaptive Mean Thresholding&#x27;</span>, <span class="hljs-string">&#x27;Adaptive Gaussian Thresholding&#x27;</span>]<br>images = [img, th1, th2, th3]</p>
<p><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">4</span>):<br>    plt.subplot(<span class="hljs-number">2</span>,<span class="hljs-number">2</span>,i+<span class="hljs-number">1</span>),plt.imshow(images[i],<span class="hljs-string">&#x27;gray&#x27;</span>)<br>    plt.title(titles[i])<br>    plt.xticks([]),plt.yticks([])<br>plt.show()</code></pre>:hexoPostRenderEscape–&gt;<br><a href="WEBRESOURCE6f6d04f3d8979190b2cb172fb60e9a6c" title="image.png" class="gallery-item"><img src="WEBRESOURCE6f6d04f3d8979190b2cb172fb60e9a6c" srcset="/img/loading.gif" alt="image.png"></a></p>
<h2 id="Otsu’s-二值化"><a href="#Otsu’s-二值化" class="headerlink" title="Otsu’s 二值化"></a>Otsu’s 二值化</h2><p>&emsp;&emsp;前面提到的<code>cv2.threshold()</code>的第一个返回值retVal，当我们使用 Otsu’s 二值化时就会用到它。</p>
<p>&emsp;&emsp;在使用全局(简单)阈值时，我们就是随便给了一个数来做阈值，那我们怎么知道我们选取的这个数的好坏呢？答案就是不停的尝试。如果是一副双峰图像（双峰图像是指图像直方图中存在两个峰）呢？我们岂不是应该在两个峰之间的峰谷选一个值作为阈值？这就是Otsu’s二值化要做的。简单来说就是对一副双峰图像自动根据其直方图计算出一个阈值。（对于非双峰图像，这种方法得到的结果可能会不理想）。</p>
<p>&emsp;&emsp;进行Otsu’s 二值化处理用到的函数还是<code>cv2.threshold()</code>，但是需要多传入一个参数(flag) cv2.THRESH_OTSU。这时要把阈值设为0。然后算法会自动找到最优阈值，这个最优阈值就是返回值retVal。如果不使用Otsu’s二值化即不传入后面的那个参数，<code>cv2.threshold()</code>返回的retVal值与设定的阈值相等。</p>
<p>&emsp;&emsp;下面的例子中，输入图像是一副带有噪声的图像。我们将使用几种方法来对其进行阈值处理，第一种方法，我们设127为全局阈值。第二种方法，直接使用Otsu二值化。第三种方法，我们首先使用一个5x5 的高斯过滤除去噪音，然后再使用Otsu二值化。这里可以看看噪音去除后对结果的影响有多大。</p>
<pre><code class="hljs python"><span class="hljs-keyword">import</span> cv2
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">from</span> matplotlib <span class="hljs-keyword">import</span> pyplot <span class="hljs-keyword">as</span> plt

img = cv2.imread(<span class="hljs-string">&#x27;fingerprint.jpg&#x27;</span>,<span class="hljs-number">0</span>)
<span class="hljs-comment"># 使用全局阈值</span>
ret1,th1 = cv2.threshold(img,<span class="hljs-number">127</span>,<span class="hljs-number">255</span>,cv2.THRESH_BINARY)
<span class="hljs-comment"># 直接使用Otsu&#x27;s二值化</span>
ret2,th2 = cv2.threshold(img,<span class="hljs-number">0</span>,<span class="hljs-number">255</span>,cv2.THRESH_BINARY+cv2.THRESH_OTSU)
<span class="hljs-comment"># 高斯滤波之后再使用Otsu&#x27;s二值化,（5,5）为高斯核的大小，0 为标准差</span>
blur = cv2.GaussianBlur(img,(<span class="hljs-number">5</span>,<span class="hljs-number">5</span>),<span class="hljs-number">0</span>)
ret3,th3 = cv2.threshold(blur,<span class="hljs-number">0</span>,<span class="hljs-number">255</span>,cv2.THRESH_BINARY+cv2.THRESH_OTSU)    <span class="hljs-comment"># 这里threshold()的阈值一定要设为0</span>

<span class="hljs-comment"># 下面画出这三种阈值处理后的目标图像和它们的直方图</span>
images = [img, <span class="hljs-number">0</span>, th1,
img, <span class="hljs-number">0</span>, th2,
blur, <span class="hljs-number">0</span>, th3]

titles = [<span class="hljs-string">&#x27;Original Noisy Image&#x27;</span>,<span class="hljs-string">&#x27;Histogram&#x27;</span>,<span class="hljs-string">&#x27;Global Thresholding (v=127)&#x27;</span>,
<span class="hljs-string">&#x27;Original Noisy Image&#x27;</span>,<span class="hljs-string">&#x27;Histogram&#x27;</span>,<span class="hljs-string">&quot;Otsu&#x27;s Thresholding&quot;</span>,
<span class="hljs-string">&#x27;Gaussian filtered Image&#x27;</span>,<span class="hljs-string">&#x27;Histogram&#x27;</span>,<span class="hljs-string">&quot;Otsu&#x27;s Thresholding&quot;</span>]

<span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">3</span>):
    plt.subplot(<span class="hljs-number">3</span>,<span class="hljs-number">3</span>,i*<span class="hljs-number">3</span>+<span class="hljs-number">1</span>),plt.imshow(images[i*<span class="hljs-number">3</span>],<span class="hljs-string">&#x27;gray&#x27;</span>)
    plt.title(titles[i*<span class="hljs-number">3</span>]), plt.xticks([]), plt.yticks([])
    plt.subplot(<span class="hljs-number">3</span>,<span class="hljs-number">3</span>,i*<span class="hljs-number">3</span>+<span class="hljs-number">2</span>),plt.hist(images[i*<span class="hljs-number">3</span>].ravel(),<span class="hljs-number">256</span>)    <span class="hljs-comment"># 使用plt.hist(参数为一维数组)画直方图，使用array.ravel()将多维数组转换为一维</span>
    plt.title(titles[i*<span class="hljs-number">3</span>+<span class="hljs-number">1</span>]), plt.xticks([]), plt.yticks([])
    plt.subplot(<span class="hljs-number">3</span>,<span class="hljs-number">3</span>,i*<span class="hljs-number">3</span>+<span class="hljs-number">3</span>),plt.imshow(images[i*<span class="hljs-number">3</span>+<span class="hljs-number">2</span>],<span class="hljs-string">&#x27;gray&#x27;</span>)
    plt.title(titles[i*<span class="hljs-number">3</span>+<span class="hljs-number">2</span>]), plt.xticks([]), plt.yticks([])
plt.show()</code></pre>
<p><a href="WEBRESOURCE55605a5458afbd85a2d688328a02f24e" title="image.png" class="gallery-item"><img src="WEBRESOURCE55605a5458afbd85a2d688328a02f24e" srcset="/img/loading.gif" alt="image.png"></a></p>
<h2 id="Otsu’s-二值化的工作原理"><a href="#Otsu’s-二值化的工作原理" class="headerlink" title="Otsu’s 二值化的工作原理"></a>Otsu’s 二值化的工作原理</h2><p>&emsp;&emsp;因为是双峰图，Otsu 算法就是要找到一个阈值（t）, 使得同一类加权方<br>差最小，需要满足下列关系式：</p>
<pre><code class="hljs math">\sigma^2_w(t) &#x3D; q_1(t)\sigma^2_1(t) + q_2(t)\sigma^2_2(t)</code></pre>
<p>其中，<br>&lt;!–hexoPostRenderEscape:<pre><code class="hljs math">q_1(t) &#x3D; \sum_&#123;i&#x3D;1&#125;^t P(i)\hspace&#123;2em&#125;\&amp;\hspace&#123;2em&#125; q_1(t) &#x3D; \sum_&#123;i&#x3D;t+1&#125;^I P(i)</p>
<p>\mu_1(t) &#x3D; \sum_&#123;i&#x3D;1&#125;^t &#x3D; \frac&#123;i P(i)&#125;&#123;q_1(t)&#125;\hspace&#123;2em&#125; \&amp; \hspace&#123;2em&#125;\mu_2(t) &#x3D; \sum_&#123;i&#x3D;t+1&#125;^I \frac&#123;iP(i)&#125;&#123;q_2(t)&#125;</p>
<p>\sigma_1^2(t) &#x3D; \sum_&#123;i&#x3D;1&#125;^t\left[i-\mu_1(t)\right]^2 \frac&#123;P(i)&#125;&#123;q_1(t)&#125;\hspace&#123;2em&#125; \&amp; \hspace&#123;2em&#125;\sigma_2^2(t) &#x3D; \sum_&#123;i&#x3D;t+1&#125;^I\left[i-\mu_1(t)\right]^2 \frac&#123;iP(i)&#125;&#123;q_2(t)&#125;</code></pre>:hexoPostRenderEscape–&gt;<br>其实就是在两个峰之间找到一个阈值t，将这两个峰分开，并且使每一个峰内的方差最小。</p>
<h1 id="图像平滑"><a href="#图像平滑" class="headerlink" title="图像平滑"></a>图像平滑</h1><h2 id="2D卷积"><a href="#2D卷积" class="headerlink" title="2D卷积"></a>2D卷积</h2><p>&emsp;&emsp;与数字信号一样，我们也可以对2D图像实施加低通滤波（LPF），高通滤波（HPF）等。LPF 帮助我们去除噪音，模糊图像。HPF帮助我们找到图像的边缘。OpenCV提供的函数<code>cv.filter2D()</code>可以让我们对一幅图像进行卷积操作。</p>
<p>下面我们将对一幅图像使用平均滤波器，一个5x5 的平均滤波器核如下：<br><pre><code class="hljs math">K&#x3D;\frac1&#123;25&#125;\left[\begin&#123;matrix&#125;
1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 \\[6pt]
1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 \\[6pt]
1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 \\[6pt]
1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 \\[6pt]
1 &amp; 1 &amp; 1 &amp; 1 &amp; 1
\end&#123;matrix&#125;\right]</code></pre></p>
<p>&emsp;&emsp;操作过程大致是这样的：将核放在图像的一个像素A 上，求与核对应的图像上25（5x5）个像素的和，再取平均数，用这个平均数替代像素A的值。重复以上操作直到将图像的每一个像素值都更新一边。</p>
<pre><code class="hljs python"><span class="hljs-keyword">import</span> cv2
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">from</span> matplotlib <span class="hljs-keyword">import</span> pyplot <span class="hljs-keyword">as</span> plt

img = cv2.imread(<span class="hljs-string">&#x27;opencv-logo.png&#x27;</span>)
kernel = np.ones((<span class="hljs-number">5</span>,<span class="hljs-number">5</span>),np.float32)/<span class="hljs-number">25</span>

<span class="hljs-comment">#cv.Filter2D(src, dst, kernel, anchor=(-1, -1))</span>
<span class="hljs-comment">#ddepth =&gt; desired depth of the destination image，期望的目标图像的深度</span>

dst = cv2.filter2D(img,<span class="hljs-number">-1</span>,kernel)    <span class="hljs-comment"># 当ddepth=-1时，则输出的目标图像与源图像有相同的深度</span>

plt.subplot(<span class="hljs-number">121</span>),plt.imshow(img),plt.title(<span class="hljs-string">&#x27;Original&#x27;</span>)
plt.xticks([]), plt.yticks([])
plt.subplot(<span class="hljs-number">122</span>),plt.imshow(dst),plt.title(<span class="hljs-string">&#x27;Averaging&#x27;</span>)
plt.xticks([]), plt.yticks([])
plt.show()</code></pre>
<p>以下src.depth()和ddepth的组合是可以使用的:</p>
<ul>
<li>src.depth() = CV_8U, ddepth = -1 | CV_16S | CV_32F | CV_64F</li>
<li>src.depth() = CV_16U | CV_16S, ddepth = -1 | CV_32F | CV_64F</li>
<li>src.depth() = CV_32F, ddepth = -1 | CV_32F | CV_64F</li>
<li>src.depth() = CV_64F, ddepth = -1 | CV_64F</li>
</ul>
<p><a href="WEBRESOURCEbe839a5dd3c13d2a0de23d2a6e03f88c" title="image.png" class="gallery-item"><img src="WEBRESOURCEbe839a5dd3c13d2a0de23d2a6e03f88c" srcset="/img/loading.gif" alt="image.png"></a></p>
<h2 id="图像模糊"><a href="#图像模糊" class="headerlink" title="图像模糊"></a>图像模糊</h2><p>&emsp;&emsp;使用低通滤波器可以达到图像模糊的目的，这对于去除噪音很有帮助。这个处理其实就是去除图像中的高频成分（比如：噪音，边界），所以边界也会被模糊一点。。OpenCV提供了四种模糊技术。</p>
<h3 id="平均"><a href="#平均" class="headerlink" title="平均"></a>平均</h3><p>&emsp;&emsp;这是由一个归一化卷积框完成的，它通过用卷积框覆盖区域内所有像素的平均值来代替中心元素。可以使用函数<code>cv2.blur()</code>和<code>cv2.boxFilter()</code>来完这个任务。我们需要设定卷积框的宽和高。</p>
<p>下面是一个3x3 的归一化卷积框：<br><pre><code class="hljs math">K&#x3D;\frac1&#123;9&#125;\left[\begin&#123;matrix&#125;
1 &amp; 1 &amp; 1 \\[6pt]
1 &amp; 1 &amp; 1 \\[6pt]
1 &amp; 1 &amp; 1
\end&#123;matrix&#125;\right]</code></pre><br>下面这个例子只是在上面例子做了一下更改：<br>&lt;!–hexoPostRenderEscape:<pre><code class="hljs python"><span class="hljs-keyword">import</span> cv2<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> matplotlib <span class="hljs-keyword">import</span> pyplot <span class="hljs-keyword">as</span> plt</p>
<p>img = cv2.imread(<span class="hljs-string">&#x27;opencv-logo.png&#x27;</span>)<br><span class="hljs-comment"># 使用归一化卷积来模糊图像</span><br>blur = cv2.blur(img,(<span class="hljs-number">5</span>,<span class="hljs-number">5</span>))</p>
<p>plt.subplot(<span class="hljs-number">121</span>),plt.imshow(img),plt.title(<span class="hljs-string">&#x27;Original&#x27;</span>)<br>plt.xticks([]), plt.yticks([])<br>plt.subplot(<span class="hljs-number">122</span>),plt.imshow(blur),plt.title(<span class="hljs-string">&#x27;Blurred&#x27;</span>)<br>plt.xticks([]), plt.yticks([])<br>plt.show()</code></pre>:hexoPostRenderEscape–&gt;<br><a href="WEBRESOURCE2716c0090e4386f150d10e2022219a8b" title="image.png" class="gallery-item"><img src="WEBRESOURCE2716c0090e4386f150d10e2022219a8b" srcset="/img/loading.gif" alt="image.png"></a></p>
<h3 id="高斯模糊"><a href="#高斯模糊" class="headerlink" title="高斯模糊"></a>高斯模糊</h3><p>&emsp;&emsp;现在把卷积核换成高斯核（简单来说就是，方框不变，原来每个方框的值是相等的，现在里面的值是符合高斯分布的，方框中心的值最大，其余方框根据距离中心元素的距离递减，构成一个高斯小山包。原来是求平均数现在变成求加权平均数）。<br><br>&emsp;&emsp;实现的函数是<code>cv2.GaussianBlur()</code>。我们需要指定高斯核的宽和高（必须是奇数）以及高斯函数沿X，Y 方向的标准差。如果我们只指定了X方向的的标准差，Y方向也会取相同值。如果两个标准差都是0，那么函数会根据核函数的大小自己计算。<br><br>&emsp;&emsp;高斯滤波可以有效的从图像中去除高斯噪音。如果需要的话，你也可以使用函数<code>cv2.getGaussianKernel()</code>自己构建一个高斯核。</p>
<pre><code class="hljs python"><span class="hljs-keyword">import</span> cv2
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">from</span> matplotlib <span class="hljs-keyword">import</span> pyplot <span class="hljs-keyword">as</span> plt

img = cv2.imread(<span class="hljs-string">&#x27;opencv-logo.png&#x27;</span>)
<span class="hljs-comment"># 参数0 表示要根据窗口大小（5,5）来计算高斯函数标准差</span>
blur = cv2.GaussianBlur(img,(<span class="hljs-number">5</span>,<span class="hljs-number">5</span>),<span class="hljs-number">0</span>)

plt.subplot(<span class="hljs-number">121</span>),plt.imshow(img),plt.title(<span class="hljs-string">&#x27;Original&#x27;</span>)
plt.xticks([]), plt.yticks([])
plt.subplot(<span class="hljs-number">122</span>),plt.imshow(blur),plt.title(<span class="hljs-string">&#x27;Blurred&#x27;</span>)
plt.xticks([]), plt.yticks([])
plt.show()</code></pre>
<p><a href="WEBRESOURCE1ac953b844d259ba7c2dcf2c004bbbea" title="image.png" class="gallery-item"><img src="WEBRESOURCE1ac953b844d259ba7c2dcf2c004bbbea" srcset="/img/loading.gif" alt="image.png"></a></p>
<h3 id="中值模糊"><a href="#中值模糊" class="headerlink" title="中值模糊"></a>中值模糊</h3><p>&emsp;&emsp;所谓中值模糊，就是用与卷积框对应像素的中值来替代中心像素的值。这个滤波器经常用来去除椒盐噪声。前面的滤波器都是用计算得到的一个新值来取代中心像素的值，而中值滤波是用中心像素周围的值来取代它。它能有效的去除噪声。卷积核的大小也应该是一个奇数。</p>
<pre><code class="hljs python"><span class="hljs-keyword">import</span> cv2
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">from</span> matplotlib <span class="hljs-keyword">import</span> pyplot <span class="hljs-keyword">as</span> plt

img = cv2.imread(<span class="hljs-string">&#x27;opencv-logo.png&#x27;</span>)
median = cv2.medianBlur(img,<span class="hljs-number">5</span>)

plt.subplot(<span class="hljs-number">121</span>),plt.imshow(img),plt.title(<span class="hljs-string">&#x27;Original&#x27;</span>)
plt.xticks([]), plt.yticks([])
plt.subplot(<span class="hljs-number">122</span>),plt.imshow(blur),plt.title(<span class="hljs-string">&#x27;Blurred&#x27;</span>)
plt.xticks([]), plt.yticks([])
plt.show()</code></pre>
<p><a href="WEBRESOURCEe17bb2a5a343fca2cc43a6391c9c080d" title="image.png" class="gallery-item"><img src="WEBRESOURCEe17bb2a5a343fca2cc43a6391c9c080d" srcset="/img/loading.gif" alt="image.png"></a></p>
<h3 id="双边滤波"><a href="#双边滤波" class="headerlink" title="双边滤波"></a>双边滤波</h3><p>&emsp;&emsp;函数<code>cv2.bilateralFilter()</code>能在保持边界清晰的情况下有效的去除噪音，但是这种操作与其他滤波器相比会比较慢。<br><br>&emsp;&emsp;我们已经知道高斯滤波器是求中心点邻近区域像素的高斯加权平均值，这种高斯滤波器只考虑了像素之间的空间关系(像素分布)，而没有考虑像素值之间的关系（像素的相似度），所以这种方法并不会考虑一个像素是否位于边界，因此边界也会被模糊掉，而这不是我们想要的。<br><br>&emsp;&emsp;双边滤波同时使用了空间高斯权重和灰度值相似性高斯权重。空间高斯函数确保只有邻近区域的像素对中心点有影响，灰度值相似性高斯函数确保只有与中心像素灰度值相近的才会被用来做模糊运算。所以这种方法会确保边界不会被模糊掉，因为边界处的灰度值变化会比较大。</p>
<pre><code class="hljs python"><span class="hljs-keyword">import</span> cv2
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">from</span> matplotlib <span class="hljs-keyword">import</span> pyplot <span class="hljs-keyword">as</span> plt

img = cv2.imread(<span class="hljs-string">&#x27;wood.jpg&#x27;</span>)

<span class="hljs-comment"># cv2.bilateralFilter(src, d, sigmaColor, sigmaSpace)</span>
<span class="hljs-comment">#d =&gt; 过滤过程中使用的每个像素邻域的直径。</span>

<span class="hljs-comment"># 参数9表示邻域直径，两个75 分别是空间高斯函数标准差，灰度值相似性高斯函数标准差</span>
blur = cv2.bilateralFilter(img,<span class="hljs-number">9</span>,<span class="hljs-number">75</span>,<span class="hljs-number">75</span>)

plt.subplot(<span class="hljs-number">121</span>),plt.imshow(img),plt.title(<span class="hljs-string">&#x27;Original&#x27;</span>)
plt.xticks([]), plt.yticks([])
plt.subplot(<span class="hljs-number">122</span>),plt.imshow(blur),plt.title(<span class="hljs-string">&#x27;Blurred&#x27;</span>)
plt.xticks([]), plt.yticks([])
plt.show()</code></pre>
<p><a href="WEBRESOURCE2ac226620840df1928d8149e7354d22a" title="image.png" class="gallery-item"><img src="WEBRESOURCE2ac226620840df1928d8149e7354d22a" srcset="/img/loading.gif" alt="image.png"></a></p>
<p>可见，双边滤波不会模糊边界。</p>
<h1 id="形态学转换"><a href="#形态学转换" class="headerlink" title="形态学转换"></a>形态学转换</h1><p>&emsp;&emsp;形态学操作是指根据图像形状进行的简单操作。一般情况下，对二值化图像进行的操作需要输入两个参数，一个是原始图像，第二个被称为结构化元素或核，它是用来决定操作的性质的。两个基本的形态学操作是<strong>腐蚀</strong>和<strong>膨胀</strong>。他们的变体则构成了<strong>开运算</strong>，<strong>闭运算</strong>，<strong>梯度</strong>等。</p>
<h2 id="腐蚀"><a href="#腐蚀" class="headerlink" title="腐蚀"></a>腐蚀</h2><p>&emsp;&emsp;就像土壤侵蚀一样，这个操作会把前景物体的边界腐蚀掉（但是前景仍然是白色）。那这是怎么做到的呢？卷积核沿着图像滑动，如果与卷积核对应的原图像的所有像素值都是1，那么中心元素就保持原来的像素值，否则就变为零。这会产生什么影响呢？根据卷积核的大小，靠近前景的所有像素都会被腐蚀掉（变为0），所以前景物体会变小，整幅图像的白色区域会减少。这对于去除白色噪声很有用，也可以用来断开两个连在一块的物体等。</p>
<p>这里我们有一个例子，使用一个5x5 的卷积核。</p>
<pre><code class="hljs python"><span class="hljs-keyword">import</span> cv2
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np

img = cv2.imread(<span class="hljs-string">&#x27;ball.png&#x27;</span>,<span class="hljs-number">0</span>)
cv2.imshow(<span class="hljs-string">&#x27;src&#x27;</span>, img)

<span class="hljs-comment"># 构建5*5的卷积核</span>
kernel = np.ones((<span class="hljs-number">5</span>,<span class="hljs-number">5</span>),np.uint8)
<span class="hljs-comment"># 腐蚀操作</span>
erosion = cv2.erode(img,kernel,iterations = <span class="hljs-number">1</span>)

cv2.imshow(<span class="hljs-string">&#x27;dst&#x27;</span>, erosion)
cv2.waitKey(<span class="hljs-number">0</span>)
cv2.destroyAllWindows()</code></pre>
<p><a href="WEBRESOURCEa777be42c754dd331e6d0581bbc70860" title="image.png" class="gallery-item"><img src="WEBRESOURCEa777be42c754dd331e6d0581bbc70860" srcset="/img/loading.gif" alt="image.png"></a></p>
<h2 id="膨胀"><a href="#膨胀" class="headerlink" title="膨胀"></a>膨胀</h2><p>&emsp;&emsp;与腐蚀相反，与卷积核对应的原图像的像素值中只要有一个是1，中心元素的像素值就是1。所以这个操作会增加图像中的白色区域（前景）。<br><br>&emsp;&emsp;一般在去噪声时先用腐蚀再用膨胀。因为腐蚀在去掉白噪声的同时，也会使前景对象变小。所以我们再对它进行膨胀。这时噪声已经被去除了，不会再回来了，但是前景还在增加。膨胀也可以用来连接两个分开的物体。</p>
<pre><code class="hljs python"><span class="hljs-keyword">import</span> cv2
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np

img = cv2.imread(<span class="hljs-string">&#x27;j.png&#x27;</span>,<span class="hljs-number">0</span>)

cv2.namedWindow(<span class="hljs-string">&#x27;src&#x27;</span>, cv2.WINDOW_NORMAL)
cv2.namedWindow(<span class="hljs-string">&#x27;dst&#x27;</span>, cv2.WINDOW_NORMAL)

cv2.imshow(<span class="hljs-string">&#x27;src&#x27;</span>, img)

<span class="hljs-comment"># 构建5*5的卷积核</span>
kernel = np.ones((<span class="hljs-number">5</span>,<span class="hljs-number">5</span>),np.uint8)
<span class="hljs-comment"># 膨胀操作</span>
dilation = cv2.dilate(img,kernel,iterations = <span class="hljs-number">1</span>)

cv2.imshow(<span class="hljs-string">&#x27;dst&#x27;</span>, dilation)
cv2.waitKey(<span class="hljs-number">0</span>)
cv2.destroyAllWindows()</code></pre>
<p><a href="WEBRESOURCEed0707358428dcc496e018959fa39ace" title="image.png" class="gallery-item"><img src="WEBRESOURCEed0707358428dcc496e018959fa39ace" srcset="/img/loading.gif" alt="image.png"></a></p>
<h2 id="开运算"><a href="#开运算" class="headerlink" title="开运算"></a>开运算</h2><p>&emsp;&emsp;先进行腐蚀再进行膨胀就叫做开运算。，它被用来去除噪声。这里我们用到的函数是<code>cv2.morphologyEx()</code>。</p>
<pre><code class="hljs python"><span class="hljs-keyword">import</span> cv2
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np

img = cv2.imread(<span class="hljs-string">&#x27;j_noise.png&#x27;</span>,<span class="hljs-number">0</span>)

cv2.namedWindow(<span class="hljs-string">&#x27;src&#x27;</span>, cv2.WINDOW_NORMAL)
cv2.namedWindow(<span class="hljs-string">&#x27;dst&#x27;</span>, cv2.WINDOW_NORMAL)

cv2.imshow(<span class="hljs-string">&#x27;src&#x27;</span>, img)

<span class="hljs-comment"># 构建5*5的卷积核</span>
kernel = np.ones((<span class="hljs-number">5</span>,<span class="hljs-number">5</span>),np.uint8)
<span class="hljs-comment"># 开运算</span>
opening = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)

cv2.imshow(<span class="hljs-string">&#x27;dst&#x27;</span>, opening)
cv2.waitKey(<span class="hljs-number">0</span>)
cv2.destroyAllWindows()</code></pre>
<p><a href="WEBRESOURCE762aa11b1c2d969d23defba15d5d8b31" title="image.png" class="gallery-item"><img src="WEBRESOURCE762aa11b1c2d969d23defba15d5d8b31" srcset="/img/loading.gif" alt="image.png"></a></p>
<h2 id="闭运算"><a href="#闭运算" class="headerlink" title="闭运算"></a>闭运算</h2><p>闭运算其实就是先膨胀再腐蚀。它经常被用来填充前景物体中的小洞，或者前景物体上的小黑点。</p>
<pre><code class="hljs python"><span class="hljs-keyword">import</span> cv2
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np

img = cv2.imread(<span class="hljs-string">&#x27;j_noise2.png&#x27;</span>,<span class="hljs-number">0</span>)

cv2.namedWindow(<span class="hljs-string">&#x27;src&#x27;</span>, cv2.WINDOW_NORMAL)
cv2.namedWindow(<span class="hljs-string">&#x27;dst&#x27;</span>, cv2.WINDOW_NORMAL)

cv2.imshow(<span class="hljs-string">&#x27;src&#x27;</span>, img)

<span class="hljs-comment"># 构建5*5的卷积核</span>
kernel = np.ones((<span class="hljs-number">5</span>,<span class="hljs-number">5</span>),np.uint8)
<span class="hljs-comment"># 闭运算</span>
closing = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)

cv2.imshow(<span class="hljs-string">&#x27;dst&#x27;</span>, closing)
cv2.waitKey(<span class="hljs-number">0</span>)
cv2.destroyAllWindows()</code></pre>
<p><a href="WEBRESOURCEd9b007e8e78b5cb572a76841b76a08fe" title="image.png" class="gallery-item"><img src="WEBRESOURCEd9b007e8e78b5cb572a76841b76a08fe" srcset="/img/loading.gif" alt="image.png"></a></p>
<h2 id="形态学梯度"><a href="#形态学梯度" class="headerlink" title="形态学梯度"></a>形态学梯度</h2><p>所谓形态学梯度，其实就是一幅图像膨胀之后与腐蚀之后的差别。结果看上去就像前景物体的轮廓。</p>
<pre><code class="hljs python"><span class="hljs-keyword">import</span> cv2
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np

img = cv2.imread(<span class="hljs-string">&#x27;j.png&#x27;</span>,<span class="hljs-number">0</span>)

<span class="hljs-comment"># 构建5*5的卷积核</span>
kernel = np.ones((<span class="hljs-number">5</span>,<span class="hljs-number">5</span>),np.uint8)
<span class="hljs-comment"># 形态学梯度</span>
gradient = cv2.morphologyEx(img, cv2.MORPH_GRADIENT, kernel)

cv2.namedWindow(<span class="hljs-string">&#x27;dst&#x27;</span>, cv2.WINDOW_NORMAL)
cv2.imshow(<span class="hljs-string">&#x27;dst&#x27;</span>, gradient)
cv2.waitKey(<span class="hljs-number">0</span>)
cv2.destroyAllWindows()</code></pre>
<p><a href="WEBRESOURCEf602f3a3dc9c819e58138b36c1b4cbfa" title="image.png" class="gallery-item"><img src="WEBRESOURCEf602f3a3dc9c819e58138b36c1b4cbfa" srcset="/img/loading.gif" alt="image.png"></a></p>
<h2 id="礼帽"><a href="#礼帽" class="headerlink" title="礼帽"></a>礼帽</h2><p>原始图像与进行开运算之后得到的图像的差。</p>
<p>下面的例子是用一个9x9 的核进行礼帽操作的结果：<br>&lt;!–hexoPostRenderEscape:<pre><code class="hljs python"><span class="hljs-keyword">import</span> cv2<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np</p>
<p>img = cv2.imread(<span class="hljs-string">&#x27;j.png&#x27;</span>,<span class="hljs-number">0</span>)</p>
<p>cv2.namedWindow(<span class="hljs-string">&#x27;src&#x27;</span>, cv2.WINDOW_NORMAL)<br>cv2.namedWindow(<span class="hljs-string">&#x27;dst&#x27;</span>, cv2.WINDOW_NORMAL)</p>
<p>cv2.imshow(<span class="hljs-string">&#x27;src&#x27;</span>, img)</p>
<p><span class="hljs-comment"># 构建9*9的卷积核</span><br>kernel = np.ones((<span class="hljs-number">9</span>,<span class="hljs-number">9</span>),np.uint8)<br><span class="hljs-comment"># 礼帽操作</span><br>tophat = cv2.morphologyEx(img, cv2.MORPH_TOPHAT, kernel)</p>
<p>cv2.imshow(<span class="hljs-string">&#x27;dst&#x27;</span>, tophat)<br>cv2.waitKey(<span class="hljs-number">0</span>)<br>cv2.destroyAllWindows()</code></pre>:hexoPostRenderEscape–&gt;<br><a href="WEBRESOURCE6b99891b1be3f86951761e825a72d774" title="image.png" class="gallery-item"><img src="WEBRESOURCE6b99891b1be3f86951761e825a72d774" srcset="/img/loading.gif" alt="image.png"></a></p>
<h2 id="黑帽"><a href="#黑帽" class="headerlink" title="黑帽"></a>黑帽</h2><p>进行闭运算之后得到的图像与原始图像的差。</p>
<pre><code class="hljs python"><span class="hljs-keyword">import</span> cv2
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np

img = cv2.imread(<span class="hljs-string">&#x27;j.png&#x27;</span>,<span class="hljs-number">0</span>)

cv2.namedWindow(<span class="hljs-string">&#x27;src&#x27;</span>, cv2.WINDOW_NORMAL)
cv2.namedWindow(<span class="hljs-string">&#x27;dst&#x27;</span>, cv2.WINDOW_NORMAL)

cv2.imshow(<span class="hljs-string">&#x27;src&#x27;</span>, img)

<span class="hljs-comment"># 构建9*9的卷积核</span>
kernel = np.ones((<span class="hljs-number">9</span>,<span class="hljs-number">9</span>),np.uint8)
<span class="hljs-comment"># 黑帽操作</span>
blackhat = cv2.morphologyEx(img, cv2.MORPH_BLACKHAT, kernel)

cv2.imshow(<span class="hljs-string">&#x27;dst&#x27;</span>, blackhat)
cv2.waitKey(<span class="hljs-number">0</span>)
cv2.destroyAllWindows()</code></pre>
<p><a href="WEBRESOURCEdc9279e9e27cd4ab249d247a0b31864c" title="image.png" class="gallery-item"><img src="WEBRESOURCEdc9279e9e27cd4ab249d247a0b31864c" srcset="/img/loading.gif" alt="image.png"></a></p>
<h2 id="形态学操作之间的关系"><a href="#形态学操作之间的关系" class="headerlink" title="形态学操作之间的关系"></a>形态学操作之间的关系</h2><p><a href="WEBRESOURCEe3adb9726a76595465e2f9e31cab6fd4" title="image.png" class="gallery-item"><img src="WEBRESOURCEe3adb9726a76595465e2f9e31cab6fd4" srcset="/img/loading.gif" alt="image.png"></a></p>
<h2 id="更多种类的结构化元素"><a href="#更多种类的结构化元素" class="headerlink" title="更多种类的结构化元素"></a>更多种类的结构化元素</h2><p>&emsp;&emsp;在前面的例子中，我们使用的都是Numpy 构建的结构化元素(核(，它是正方形的，但<br>有时我们需要构建一个椭圆形/圆形的核。为了实现这种要求，OpenCV提供了函数<code>cv2.getStructuringElement()</code>。你只需要告诉他你需要的核的形状和大小它会自动帮你生成特定形状的核。</p>
<pre><code class="hljs lsl"># Rectangular Kernel，正方形核
&gt;&gt;&gt; cv2.getStructuringElement(cv2.MORPH_RECT,(<span class="hljs-number">5</span>,<span class="hljs-number">5</span>))
array([[<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>],
       [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>],
       [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>],
       [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>],
       [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]], dtype=uint8)

# Elliptical Kernel，椭圆形核
&gt;&gt;&gt; cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(<span class="hljs-number">5</span>,<span class="hljs-number">5</span>))
array([[<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],
[<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>],
[<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>],
[<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>],
[<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>]], dtype=uint8)

# Cross-shaped Kernel,十字形核
&gt;&gt;&gt; cv2.getStructuringElement(cv2.MORPH_CROSS,(<span class="hljs-number">5</span>,<span class="hljs-number">5</span>))
array([[<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],
[<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],
[<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>],
[<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],
[<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>]], dtype=uint8)</code></pre>
<p><a href="WEBRESOURCE65e3b15ad1b26e9f29d63db0adb2726a" title="image.png" class="gallery-item"><img src="WEBRESOURCE65e3b15ad1b26e9f29d63db0adb2726a" srcset="/img/loading.gif" alt="image.png"></a></p>
<h1 id="图像梯度"><a href="#图像梯度" class="headerlink" title="图像梯度"></a>图像梯度</h1><p>&emsp;&emsp;所谓图像梯度，简单来说，就是求导。OpenCV提供了三种不同的梯度滤波器，或者说是高通滤波器：Sobel，Scharr 和Laplacian。<br><br>&emsp;&emsp;Sobel，Scharr 其实就是求一阶或二阶导数，Scharr 是对Sobel（使用小的卷积核求解梯度角度时）的优化。Laplacian 则是求二阶导数。</p>
<h2 id="Sobel-算子和Scharr-算子"><a href="#Sobel-算子和Scharr-算子" class="headerlink" title="Sobel 算子和Scharr 算子"></a>Sobel 算子和Scharr 算子</h2><p>&emsp;&emsp;Sobel 算子是高斯平滑与微分操作的结合体，所以它的抗噪声能力很好。你可以设定求导的方向（xorder 或yorder）。还可以设定使用的卷积核的大小（ksize）。如果ksize=-1，可以使用3x3 的Scharr 滤波器，它的的效果要比3x3 的Sobel 滤波器好（而且速度相同，所以在使用3x3 滤波器时应该尽量使用Scharr 滤波器）。</p>
<p>3x3 的Scharr 滤波器卷积核如下：</p>
<p><a href="WEBRESOURCEb5f3da01120ff85e176c0f1ecd1e0255" title="image.png" class="gallery-item"><img src="WEBRESOURCEb5f3da01120ff85e176c0f1ecd1e0255" srcset="/img/loading.gif" alt="image.png"></a></p>
<h2 id="Laplacian-算子"><a href="#Laplacian-算子" class="headerlink" title="Laplacian 算子"></a>Laplacian 算子</h2><p>&emsp;&emsp;拉普拉斯算子可以使用二阶导数的形式定义，可假设其离散实现类似于二阶Sobel 导数，事实上，OpenCV 在计算拉普拉斯算子时直接调用的Sobel 算子。</p>
<p>其计算公式如下：</p>
<pre><code class="hljs math">\Delta src &#x3D; \frac&#123;\partial^2 src&#125;&#123;\partial x^2&#125; + \frac&#123;\partial^2 src&#125;&#123;\partial y^2&#125;</code></pre>
<p>拉普拉斯滤波器使用的卷积核：<br><pre><code class="hljs math">kernel &#x3D; \left[\begin&#123;matrix&#125;
0 &amp; 1 &amp; 0 \\[6pt]
1 &amp; -4 &amp; 1 \\[6pt]
0 &amp; 1 &amp; 0
\end&#123;matrix&#125;\right]</code></pre><br><a href="WEBRESOURCE3e12c2e35fea1c1173036424265563e5" title="image.png" class="gallery-item"><img src="WEBRESOURCE3e12c2e35fea1c1173036424265563e5" srcset="/img/loading.gif" alt="image.png"></a></p>
<p>&emsp;&emsp;上面反复提到过，我们可以通过设置输出类型为-1来让输出图像的深度（数据类型）与原图像保持一致，但可以看到，我们在代码中使用的并不是-1，而是cv2.CV_64F。这是为什么呢？<br><br>&emsp;&emsp;这里可以想象一下一个从黑到白的边界的导数是整数，而一个从白到黑的边界点导数却是负数。如果原图像的深度是np.int8，那么所有的负值都会被截断变成0，换句话说就是会把边界信息丢失掉。<br><br>&emsp;&emsp;所以如果这两种边界都想检测到，最好的的办法就是将输出的数据类型设置的更高，比如cv2.CV_16S，cv2.CV_64F 等，再取绝对值将它转回到cv2.CV_8U类型。</p>
<pre><code class="hljs python"><span class="hljs-keyword">import</span> cv2
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">from</span> matplotlib <span class="hljs-keyword">import</span> pyplot <span class="hljs-keyword">as</span> plt

img = cv2.imread(<span class="hljs-string">&#x27;boxs.png&#x27;</span>,<span class="hljs-number">0</span>)
<span class="hljs-comment"># 输出类型设为cv2.CV_8U</span>
sobelx8u = cv2.Sobel(img,cv2.CV_8U,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,ksize=<span class="hljs-number">5</span>)

<span class="hljs-comment"># 输出类型设为cv2.CV_64F，然后取其绝对值转换为cv2.CV_8U类型</span>
sobelx64f = cv2.Sobel(img,cv2.CV_64F,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,ksize=<span class="hljs-number">5</span>)
abs_sobel64f = np.absolute(sobelx64f)
sobel_8u = np.uint8(abs_sobel64f)

plt.subplot(<span class="hljs-number">1</span>,<span class="hljs-number">3</span>,<span class="hljs-number">1</span>),plt.imshow(img,cmap = <span class="hljs-string">&#x27;gray&#x27;</span>)
plt.title(<span class="hljs-string">&#x27;Original&#x27;</span>), plt.xticks([]), plt.yticks([])
plt.subplot(<span class="hljs-number">1</span>,<span class="hljs-number">3</span>,<span class="hljs-number">2</span>),plt.imshow(sobelx8u,cmap = <span class="hljs-string">&#x27;gray&#x27;</span>)
plt.title(<span class="hljs-string">&#x27;Sobel CV_8U&#x27;</span>), plt.xticks([]), plt.yticks([])
plt.subplot(<span class="hljs-number">1</span>,<span class="hljs-number">3</span>,<span class="hljs-number">3</span>),plt.imshow(sobel_8u,cmap = <span class="hljs-string">&#x27;gray&#x27;</span>)
plt.title(<span class="hljs-string">&#x27;Sobel abs(CV_64F)&#x27;</span>), plt.xticks([]), plt.yticks([])
plt.show()</code></pre>
<p><a href="WEBRESOURCE8723a5158f88e0a611d4ac68ee1b77cb" title="image.png" class="gallery-item"><img src="WEBRESOURCE8723a5158f88e0a611d4ac68ee1b77cb" srcset="/img/loading.gif" alt="image.png"></a></p>
<h1 id="Canny边缘检测"><a href="#Canny边缘检测" class="headerlink" title="Canny边缘检测"></a>Canny边缘检测</h1><p>&emsp;&emsp;Canny 边缘检测是一种非常流行的边缘检测算法，是John F.Canny 在1986 年提出的，它是一个由很多步组成的算法。</p>
<h2 id="去噪"><a href="#去噪" class="headerlink" title="去噪"></a>去噪</h2><p>由于边缘检测很容易受到噪声影响，所以第一步是使用5x5 的高斯滤波器去除噪声。</p>
<h2 id="计算图像梯度"><a href="#计算图像梯度" class="headerlink" title="计算图像梯度"></a>计算图像梯度</h2><p>&emsp;&emsp;对平滑后的图像使用Sobel 算子计算水平方向和竖直方向的一阶导数（图像梯度，Gx 和Gy）。根据得到的这两幅梯度图（Gx 和Gy）找到边界的梯度和方向，公式如下：</p>
<pre><code class="hljs math">Edge\_Gradient(G) &#x3D; \sqrt&#123;G_x^2 + G_y^2&#125;

Angle(\theta) &#x3D; tan^&#123;-1&#125;\left(\frac&#123;G_x&#125;&#123;G_y&#125;\right)</code></pre>
<p>梯度的方向一般总是与边界垂直。梯度方向被归为四类：垂直，水平，和两个对角线。</p>
<h2 id="非极大值抑制"><a href="#非极大值抑制" class="headerlink" title="非极大值抑制"></a>非极大值抑制</h2><p>&emsp;&emsp;在获得梯度的方向和大小之后，应该对整幅图像做一个扫描，去除那些非边界上的点。对每一个像素进行检查，看这个点的梯度是不是周围具有相同梯度方向的点中最大的。</p>
<p>如下图所示:</p>
<p><a href="WEBRESOURCEe338c845d3af82ca5445866da8146d5c" title="image.png" class="gallery-item"><img src="WEBRESOURCEe338c845d3af82ca5445866da8146d5c" srcset="/img/loading.gif" alt="image.png"></a></p>
<h2 id="滞后阈值"><a href="#滞后阈值" class="headerlink" title="滞后阈值"></a>滞后阈值</h2><p>&emsp;&emsp;现在要确定的是哪些边界才是真正的边界。这时我们需要设置两个阈值：minVal 和maxVal。当图像的灰度梯度高于maxVal 时被认为是真的边界，那些低于minVal 的开始被认为是边界的像素会被抛弃。如果介于两者之间的话，就要看这个点是否与某个被确定为真正的边界点相连，如果是就认为它也是边界点，如果不是就抛弃。</p>
<p>如下图：</p>
<p><a href="WEBRESOURCEce4c16d944af5656a97c6e9bc01397ad" title="image.png" class="gallery-item"><img src="WEBRESOURCEce4c16d944af5656a97c6e9bc01397ad" srcset="/img/loading.gif" alt="image.png"></a></p>
<p>&emsp;&emsp;我们分析一下上图，A 高于阈值maxVal ，所以是真正的边界点，C 虽然低于maxVal 但高于minVal 并且与A 相连，所以也被认为是真正的边界点。而B 就会被抛弃，因为它不仅低于maxVal 而且不与真正的边界点相连。<br><br>&emsp;&emsp;可见，选择合适的maxVal和minVal对于能否得到好的结果非常重要。在这一步，一些小的噪声点也会被除去，因为我们假设边界都是一些长的线段。</p>
<h1 id="OpenCV-中的Canny-边界检测"><a href="#OpenCV-中的Canny-边界检测" class="headerlink" title="OpenCV 中的Canny 边界检测"></a>OpenCV 中的Canny 边界检测</h1><p>&emsp;&emsp;实际上，在OpenCV中使用Canny算法进行边缘检测没有我们想的那么复杂，OpenCV对这几步操作进行了封装，只需要使用一个函数：<code>cv2.Canny()</code>，就可以完成以上几步。<br><br>&emsp;&emsp;这个函数的第一个参数是输入图像。第二和第三个分别是minVal和maxVal。第四个参数设置用来计算图像梯度的Sobel卷积核的大小，默认值为3。最后一个参数是L2gradient，它可以用来设定求梯度大小的方程。如果设为True，就会使用我们上面提到过的方程，否则将使用<code>$Edge\_Gradient(G) = |G_x^2| + |G_y^2|$</code>作为代替，默认值为False。</p>
<pre><code class="hljs python"><span class="hljs-keyword">import</span> cv2
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">from</span> matplotlib <span class="hljs-keyword">import</span> pyplot <span class="hljs-keyword">as</span> plt

img = cv2.imread(<span class="hljs-string">&#x27;ball.png&#x27;</span>,<span class="hljs-number">0</span>)
<span class="hljs-comment"># cv2.Canny(src, minVal, maxVal)</span>
edges = cv2.Canny(img,<span class="hljs-number">100</span>,<span class="hljs-number">200</span>)

plt.subplot(<span class="hljs-number">121</span>),plt.imshow(img,cmap = <span class="hljs-string">&#x27;gray&#x27;</span>)
plt.title(<span class="hljs-string">&#x27;Original Image&#x27;</span>), plt.xticks([]), plt.yticks([])
plt.subplot(<span class="hljs-number">122</span>),plt.imshow(edges,cmap = <span class="hljs-string">&#x27;gray&#x27;</span>)
plt.title(<span class="hljs-string">&#x27;Edge Image&#x27;</span>), plt.xticks([]), plt.yticks([])
plt.show()</code></pre>
<p><a href="WEBRESOURCE50bc7b9133bc87e6fbc18cfcc74f4ac7" title="image.png" class="gallery-item"><img src="WEBRESOURCE50bc7b9133bc87e6fbc18cfcc74f4ac7" srcset="/img/loading.gif" alt="image.png"></a></p>
<h1 id="图像金字塔"><a href="#图像金字塔" class="headerlink" title="图像金字塔"></a>图像金字塔</h1><p>&emsp;&emsp;一般情况下，我们要处理是一副具有固定分辨率的图像。但是有些情况下，我们需要对同一图像的不同分辨率的子图像进行处理。比如，我们要在一幅图像中查找某个目标，比如脸，我们不知道目标在图像中的尺寸大小。<br><br>&emsp;&emsp;这种情况下，我们需要创建一组图像，这些图像是具有不同分辨率的原始图像。我们把这组图像叫做图像金字塔（简单来说就是同一图像的不同分辨率的子图集合）。如果我们把最大的图像放在底部，最小的放在顶部，看起来像一座金字塔，图像金字塔因而得名。<br><br>&emsp;&emsp;有两类图像金字塔：<strong>高斯金字塔</strong>和<strong>拉普拉斯金字塔</strong>。高斯金字塔的顶部是通过将底部图像中的连续的行和列去除得到的。顶部图像中的每个像素值等于下一层图像中5 个像素的高斯加权平均值。这样，操作一次一个M <em> N 的图像就变成了一个M/2 </em> N/2的图像。所以这幅图像的面积就变为原来图像面积的四分之一。<br><br>&emsp;&emsp;连续进行这样的操作我们就会得到一个分辨率不断下降的图像金字塔。我们可以使用函数<code>cv2.pyrDown()</code>和<code>cv2.pyrUp()</code>来构建图像金字塔。</p>
<p>&emsp;&emsp;函数<code>cv2.pyrDown()</code>从一个高分辨率大尺寸的图像向上构建一个金子塔（尺寸变小，分辨率降低）。</p>
<p>&emsp;&emsp;函数<code>cv2.pyrUp()</code>则从一个低分辨率小尺寸的图像向下构建一个金子塔（尺寸变大，但分辨率不会增加）。</p>
<h1 id="OpenCV中的轮廓"><a href="#OpenCV中的轮廓" class="headerlink" title="OpenCV中的轮廓"></a>OpenCV中的轮廓</h1><h2 id="什么是轮廓"><a href="#什么是轮廓" class="headerlink" title="什么是轮廓"></a>什么是轮廓</h2><p>&emsp;&emsp;轮廓可以简单认为是将连续的点（连着边界）连在一起的曲线，具有相同的颜色或者灰度。轮廓在形状分析和物体的检测和识别中很有用。</p>
<ul>
<li>为了更加准确，要使用二值化图像。在寻找轮廓之前，要进行阈值化处理或者Canny 边界检测。</li>
<li>查找轮廓的函数会修改原始图像。如果你在找到轮廓之后还想使用原始图像的话，你应该将原始图像存储到其他变量中。</li>
<li>在OpenCV 中，查找轮廓就像在黑色背景中超白色物体。你应该记住，要找的物体应该是白色而背景应该是黑色。</li>
</ul>
<p>让我们看看如何在OpenCV中使用<code>cv2.findContours()</code>在一个二值图像中查找轮廓：</p>
<p>&emsp;&emsp;该函数有三个参数，第一个是输入图像，第二个是轮廓检索模式，第三个是轮廓近似方法。返回值有三个，第一个是图像，第二个是轮廓，第三个是（轮廓的）层析结构。轮廓（第二个返回值）是一个Python列表，其中存储着图像中的所有轮廓。每一个轮廓都是一个Numpy 数组，包含对象边界点（x，y）的坐标。</p>
<h2 id="怎样绘制轮廓"><a href="#怎样绘制轮廓" class="headerlink" title="怎样绘制轮廓"></a>怎样绘制轮廓</h2><p>&emsp;&emsp;函数<code>cv2.drawContours()</code>可以被用来绘制轮廓。它可以根据你提供的边界点绘制任何形状。它的第一个参数是原始图像，第二个参数是轮廓，一个Python列表。第三个参数是轮廓的索引（在绘制独立轮廓是很有用，当设置为-1时表示绘制所有轮廓）。接下来的参数是轮廓的颜色和厚度等。</p>
<p>下面的例子在一幅图像上绘制所有的轮廓：</p>
<pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> cv2

im = cv2.imread(<span class="hljs-string">&#x27;test.jpg&#x27;</span>)
imgray = cv2.cvtColor(im,cv2.COLOR_BGR2GRAY)
ret,thresh = cv2.threshold(imgray,<span class="hljs-number">127</span>,<span class="hljs-number">255</span>,<span class="hljs-number">0</span>)
image, contours, hierarchy = cv2.findContours(thresh,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)</code></pre>
<p>使用以下代码可以绘制单个独立的轮廓：<br><pre><code class="hljs apache"><span class="hljs-attribute">img</span> = cv<span class="hljs-number">2</span>.drawContour(img, contours, -<span class="hljs-number">1</span>, (<span class="hljs-number">0</span>,<span class="hljs-number">255</span>,<span class="hljs-number">0</span>), <span class="hljs-number">3</span>)</code></pre></p>
<h2 id="轮廓特征"><a href="#轮廓特征" class="headerlink" title="轮廓特征"></a>轮廓特征</h2><h3 id="矩"><a href="#矩" class="headerlink" title="矩"></a>矩</h3><p>图像的矩可以帮助我们计算图像的质心，面积等。</p>
<pre><code class="hljs python"><span class="hljs-keyword">import</span> cv2
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
img = cv2.imread(<span class="hljs-string">&#x27;ball.png&#x27;</span>,<span class="hljs-number">0</span>)

ret,thresh = cv2.threshold(img,<span class="hljs-number">127</span>,<span class="hljs-number">255</span>,<span class="hljs-number">0</span>)
contours,hierarchy = cv2.findContours(thresh, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>)
cnt = contours[<span class="hljs-number">0</span>]
M = cv2.moments(cnt)    <span class="hljs-comment"># 使用cv2.moments()取得轮廓的矩，返回值是字典类型</span>
print(M)</code></pre>
<p><a href="WEBRESOURCEd288752d7ed729de88cd5eebfd3e5ac4" title="image.png" class="gallery-item"><img src="WEBRESOURCEd288752d7ed729de88cd5eebfd3e5ac4" srcset="/img/loading.gif" alt="image.png"></a></p>
<p>根据这些矩的值，我们可以计算出对象的重心: <code>$C_x = \frac&#123;M_&#123;10&#125;&#125;&#123;M_&#123;100&#125;&#125;, C_y=\frac&#123;M_&#123;01&#125;&#125;&#123;M_&#123;100&#125;&#125;$</code>，亦即：<br><pre><code class="hljs ini"><span class="hljs-attr">cx</span> = int(M[<span class="hljs-string">&#x27;m10&#x27;</span>]/M[<span class="hljs-string">&#x27;m00&#x27;</span>])
<span class="hljs-attr">cy</span> = int(M[<span class="hljs-string">&#x27;m01&#x27;</span>]/M[<span class="hljs-string">&#x27;m00&#x27;</span>])</code></pre></p>
<h3 id="轮廓面积"><a href="#轮廓面积" class="headerlink" title="轮廓面积"></a>轮廓面积</h3><p>&emsp;&emsp;轮廓的面积可以使用函数<code>cv2.contourArea()</code>计算得到，也可以使用矩（0 阶矩），即M[‘m00’]。</p>
<pre><code class="hljs python"><span class="hljs-keyword">import</span> cv2
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np

img = cv2.imread(<span class="hljs-string">&#x27;ml.png&#x27;</span>,<span class="hljs-number">0</span>)

ret,thresh = cv2.threshold(img,<span class="hljs-number">127</span>,<span class="hljs-number">255</span>,<span class="hljs-number">0</span>)
contours,hierarchy = cv2.findContours(thresh, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>)
cnt = contours[<span class="hljs-number">0</span>]
perimeter = cv2.arcLength(cnt,<span class="hljs-literal">True</span>)
print(perimeter)</code></pre>
<p><a href="WEBRESOURCE84773f1a7592cce78842eef3d9881a67" title="image.png" class="gallery-item"><img src="WEBRESOURCE84773f1a7592cce78842eef3d9881a67" srcset="/img/loading.gif" alt="image.png"></a></p>
<h3 id="轮廓周长"><a href="#轮廓周长" class="headerlink" title="轮廓周长"></a>轮廓周长</h3><p>&emsp;&emsp;也被称为弧长。可以使用函数<code>cv2.arcLength()</code> 计算得到。这个函数的第二参数可以用来指定对象的形状是闭合的（True），还是打开的（一条曲线）。</p>
<pre><code class="hljs python"><span class="hljs-keyword">import</span> cv2
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np

img = cv2.imread(<span class="hljs-string">&#x27;ball.png&#x27;</span>,<span class="hljs-number">0</span>)

ret,thresh = cv2.threshold(img,<span class="hljs-number">127</span>,<span class="hljs-number">255</span>,<span class="hljs-number">0</span>)
contours,hierarchy = cv2.findContours(thresh, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>)
perimeter = cv2.arcLength(contours,<span class="hljs-literal">True</span>)
print(perimeter)</code></pre>
<p><a href="WEBRESOURCE8325e6507dcdf068ad2fc1ca6efd0f9e" title="image.png" class="gallery-item"><img src="WEBRESOURCE8325e6507dcdf068ad2fc1ca6efd0f9e" srcset="/img/loading.gif" alt="image.png"></a></p>
<h3 id="轮廓近似"><a href="#轮廓近似" class="headerlink" title="轮廓近似"></a>轮廓近似</h3><p>&emsp;&emsp;将轮廓形状近似到另外一种由更少点组成的轮廓形状，新轮廓的点的数目由我们设定的准确度来决定。使用的是Douglas-Peucker算法。</p>
<p>&emsp;&emsp;为了帮助理解，假设我们要在一幅图像中查找一个矩形，但是由于图像的种种原因，我们不能得到一个完美的矩形，而是一个“坏形状”。现在你就可以使用这个函数来近似这个形状了。这个函数的第二个参数叫epsilon，它是从原始轮廓到近似轮廓的最大距离。它是一个准确度参数。选择一个好的epsilon 对于得到满意结果非常重要。</p>
<pre><code class="hljs python"><span class="hljs-keyword">import</span> cv2
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np

img = cv2.imread(<span class="hljs-string">&#x27;ml.png&#x27;</span>,<span class="hljs-number">0</span>)

ret,thresh = cv2.threshold(img,<span class="hljs-number">127</span>,<span class="hljs-number">255</span>,<span class="hljs-number">0</span>)
contours,hierarchy = cv2.findContours(thresh, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>)
cnt = contours[<span class="hljs-number">0</span>]
epsilon = <span class="hljs-number">0.1</span>*cv2.arcLength(cnt,<span class="hljs-literal">True</span>)
approx = cv2.approxPolyDP(cnt,epsilon,<span class="hljs-literal">True</span>)
print(approx)</code></pre>
<p><a href="WEBRESOURCE329b0c9dc2a9587cb959bcadf6cf3a53" title="image.png" class="gallery-item"><img src="WEBRESOURCE329b0c9dc2a9587cb959bcadf6cf3a53" srcset="/img/loading.gif" alt="image.png"></a></p>
<h3 id="凸包"><a href="#凸包" class="headerlink" title="凸包"></a>凸包</h3><p>&emsp;&emsp;凸包与轮廓相似，但它们是不同的两个特征，虽然有些情况下它们给出的结果是一样的。函数<code>cv2.convexHull()</code>可以用来检测一个曲线是否具有凸性缺陷，并能纠正缺陷。<br><br>&emsp;&emsp;一般来说，凸性曲线总是凸出来的，至少是平的。如果有地方凹进去了就被叫做凸性缺陷。例如下图中的手。红色曲线显示了手的凸包，凸性缺陷被双箭头标出来了。</p>
<p><a href="WEBRESOURCE1d737d91ebf7db1e7db78bd9a1299564" title="image.png" class="gallery-item"><img src="WEBRESOURCE1d737d91ebf7db1e7db78bd9a1299564" srcset="/img/loading.gif" alt="image.png"></a></p>
<p>计算轮廓的凸包需要使用cv2.covexHull()函数：<br><pre><code class="hljs reasonml">hull = cv2.convex<span class="hljs-constructor">Hull(<span class="hljs-params">points</span>[, <span class="hljs-params">hull</span>[, <span class="hljs-params">clockwise</span>[, <span class="hljs-params">returnPoints</span>]]</span></code></pre><br>它的各参数含义如下：</p>
<ul>
<li>points 我们要传入的轮廓</li>
<li>hull 输出的像素列表，通常不需要</li>
<li>clockwise 方向标志。如果设置为True，则输出的凸包是顺时针方向的，否则为逆时针方向。</li>
<li>returnPoints 默认值为True,它会返回凸包上点的坐标。如果设置为False，就会返回与凸包点对应的轮廓上的点。</li>
</ul>
<pre><code class="hljs python"><span class="hljs-keyword">import</span> cv2
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np

img = cv2.imread(<span class="hljs-string">&#x27;ml.png&#x27;</span>,<span class="hljs-number">0</span>)

ret,thresh = cv2.threshold(img,<span class="hljs-number">127</span>,<span class="hljs-number">255</span>,<span class="hljs-number">0</span>)
contours,hierarchy = cv2.findContours(thresh, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>)
cnt = contours[<span class="hljs-number">0</span>]
hull = cv2.convexHull(cnt)    <span class="hljs-comment"># 计算凸包</span>
print(hull)</code></pre>
<p><a href="WEBRESOURCE6a0aa9204bedf71d015d407e50f1fc63" title="image.png" class="gallery-item"><img src="WEBRESOURCE6a0aa9204bedf71d015d407e50f1fc63" srcset="/img/loading.gif" alt="image.png"></a></p>
<h3 id="凸性检测"><a href="#凸性检测" class="headerlink" title="凸性检测"></a>凸性检测</h3><p>函数cv2.isContourConvex() 可以用来检测一个曲线是不是凸的，它只能返回True 或False。</p>
<pre><code class="hljs python"><span class="hljs-keyword">import</span> cv2
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np

img = cv2.imread(<span class="hljs-string">&#x27;ml.png&#x27;</span>,<span class="hljs-number">0</span>)

ret,thresh = cv2.threshold(img,<span class="hljs-number">127</span>,<span class="hljs-number">255</span>,<span class="hljs-number">0</span>)
contours,hierarchy = cv2.findContours(thresh, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>)
cnt = contours[<span class="hljs-number">0</span>]
k = cv2.isContourConvex(cnt)
print(k)</code></pre>
<p><a href="WEBRESOURCEdc0872e13c35bda8af71a382c384e00a" title="image.png" class="gallery-item"><img src="WEBRESOURCEdc0872e13c35bda8af71a382c384e00a" srcset="/img/loading.gif" alt="image.png"></a></p>
<h3 id="边界矩形"><a href="#边界矩形" class="headerlink" title="边界矩形"></a>边界矩形</h3><p>有两类边界矩形。</p>
<p><strong>直边界矩形</strong> 一个直矩形（就是没有旋转的矩形）是不会考虑对象是否旋转的，所以这个边界矩形的面积不是最小的。可以使用函数<code>cv2.boundingRect()</code>查找得到。</p>
<pre><code class="hljs python"><span class="hljs-keyword">import</span> cv2
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np

img = cv2.imread(<span class="hljs-string">&#x27;lightning.png&#x27;</span>,<span class="hljs-number">0</span>)

ret,thresh = cv2.threshold(img,<span class="hljs-number">127</span>,<span class="hljs-number">255</span>,<span class="hljs-number">0</span>)
contours,hierarchy = cv2.findContours(thresh, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>)
cnt = contours[<span class="hljs-number">0</span>]

<span class="hljs-comment"># (x,y)为矩形左上角的坐标，(w,h)为矩形的宽高</span>
x,y,w,h = cv2.boundingRect(cnt)
img = cv2.rectangle(img,(x,y),(x+w,y+h),(<span class="hljs-number">255</span>,<span class="hljs-number">255</span>,<span class="hljs-number">0</span>),<span class="hljs-number">2</span>)   <span class="hljs-comment"># 画出边界矩形</span>
cv2.imshow(<span class="hljs-string">&#x27;boundingRect&#x27;</span>, img)
cv2.waitKey(<span class="hljs-number">0</span>)
cv2.destroyAllWindows()</code></pre>
<p><a href="WEBRESOURCE969817ae30b63eecb6bd765fc2e8e4b1" title="image.png" class="gallery-item"><img src="WEBRESOURCE969817ae30b63eecb6bd765fc2e8e4b1" srcset="/img/loading.gif" alt="image.png"></a></p>
<p><strong>旋转的边界矩形</strong> 这个边界矩形是面积最小的，因为它考虑了对象的旋转。用到的函数为<code>cv2.minAreaRect()</code>，返回的是一个Box2D结构，其中包含矩形左上角角点的坐标（x，y），矩形的宽和高（w，h），以及旋转角度。但是要绘制这个矩形需要矩形的4个角点，可以通过函数<code>cv2.boxPoints()</code> 获得。</p>
<pre><code class="hljs python"><span class="hljs-keyword">import</span> cv2
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np

img = cv2.imread(<span class="hljs-string">&#x27;lightning.png&#x27;</span>,<span class="hljs-number">0</span>)

ret,thresh = cv2.threshold(img,<span class="hljs-number">127</span>,<span class="hljs-number">255</span>,<span class="hljs-number">0</span>)
contours,hierarchy = cv2.findContours(thresh, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>)
cnt = contours[<span class="hljs-number">0</span>]

x,y,angle = cv2.minAreaRect(cnt)
print(angle)</code></pre>
<p>下图中，红色的矩形为直边界矩形,绿色的矩形为旋转的边界矩形:</p>
<p><a href="WEBRESOURCE79e73b40da18617690e82bdd2cc902ad" title="image.png" class="gallery-item"><img src="WEBRESOURCE79e73b40da18617690e82bdd2cc902ad" srcset="/img/loading.gif" alt="image.png"></a></p>
<h3 id="最小外接圆"><a href="#最小外接圆" class="headerlink" title="最小外接圆"></a>最小外接圆</h3><p>&emsp;&emsp;函数<code>cv2.minEnclosingCircle()</code> 可以帮我们找到一个对象的外切圆，它是所有能够包括对象的圆中面积最小的一个。</p>
<pre><code class="hljs python"><span class="hljs-keyword">import</span> cv2
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np

img = cv2.imread(<span class="hljs-string">&#x27;lightning.png&#x27;</span>,<span class="hljs-number">0</span>)

ret,thresh = cv2.threshold(img,<span class="hljs-number">127</span>,<span class="hljs-number">255</span>,<span class="hljs-number">0</span>)
contours,hierarchy = cv2.findContours(thresh, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>)
cnt = contours[<span class="hljs-number">0</span>]

(x,y),radius = cv2.minEnclosingCircle(cnt)
center = (<span class="hljs-built_in">int</span>(x),<span class="hljs-built_in">int</span>(y))
radius = <span class="hljs-built_in">int</span>(radius)
img = cv2.circle(img,center,radius,(<span class="hljs-number">0</span>,<span class="hljs-number">255</span>,<span class="hljs-number">0</span>),<span class="hljs-number">2</span>)    <span class="hljs-comment"># 画出最小外接圆</span>

cv2.imshow(<span class="hljs-string">&#x27;minEnclosingCircle&#x27;</span>, img)
cv2.waitKey(<span class="hljs-number">0</span>)
cv2.destroyAllWindows()</code></pre>
<p><a href="WEBRESOURCE47630db5070b24bec1018b64f1c2d018" title="image.png" class="gallery-item"><img src="WEBRESOURCE47630db5070b24bec1018b64f1c2d018" srcset="/img/loading.gif" alt="image.png"></a></p>
<h3 id="椭圆拟合"><a href="#椭圆拟合" class="headerlink" title="椭圆拟合"></a>椭圆拟合</h3><p>使用的函数为cv2.ellipse()，返回值其实就是旋转边界矩形的内切圆。</p>
<pre><code class="hljs python"><span class="hljs-keyword">import</span> cv2
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np

img = cv2.imread(<span class="hljs-string">&#x27;lightning.png&#x27;</span>,<span class="hljs-number">0</span>)

ret,thresh = cv2.threshold(img,<span class="hljs-number">127</span>,<span class="hljs-number">255</span>,<span class="hljs-number">0</span>)
contours,hierarchy = cv2.findContours(thresh, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>)
cnt = contours[<span class="hljs-number">0</span>]

ellipse = cv2.fitEllipse(cnt)
img = cv2.ellipse(img,ellipse,(<span class="hljs-number">255</span>,<span class="hljs-number">255</span>,<span class="hljs-number">0</span>),<span class="hljs-number">2</span>)    <span class="hljs-comment"># 在原图上画出椭圆</span>

cv2.imshow(<span class="hljs-string">&#x27;minEnclosingCircle&#x27;</span>, img)
cv2.waitKey(<span class="hljs-number">0</span>)
cv2.destroyAllWindows()</code></pre>
<p><a href="WEBRESOURCE580696ba1ecf43ffe94b697c58de41d7" title="image.png" class="gallery-item"><img src="WEBRESOURCE580696ba1ecf43ffe94b697c58de41d7" srcset="/img/loading.gif" alt="image.png"></a></p>
<h3 id="直线拟合"><a href="#直线拟合" class="headerlink" title="直线拟合"></a>直线拟合</h3><p>我们可以根据一组点拟合出一条直线，同样我们也可以为图像中的白色点拟合出一条直线。</p>
<pre><code class="hljs python"><span class="hljs-keyword">import</span> cv2
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np

img = cv2.imread(<span class="hljs-string">&#x27;lightning.png&#x27;</span>,<span class="hljs-number">0</span>)

ret,thresh = cv2.threshold(img,<span class="hljs-number">127</span>,<span class="hljs-number">255</span>,<span class="hljs-number">0</span>)
contours,hierarchy = cv2.findContours(thresh, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>)
cnt = contours[<span class="hljs-number">0</span>]

rows,cols = img.shape[:<span class="hljs-number">2</span>]
[vx,vy,x,y] = cv2.fitLine(cnt, cv2.DIST_L2,<span class="hljs-number">0</span>,<span class="hljs-number">0.01</span>,<span class="hljs-number">0.01</span>)
lefty = <span class="hljs-built_in">int</span>((-x*vy/vx) + y)
righty = <span class="hljs-built_in">int</span>(((cols-x)*vy/vx)+y)
img = cv2.line(img,(cols<span class="hljs-number">-1</span>,righty),(<span class="hljs-number">0</span>,lefty),(<span class="hljs-number">0</span>,<span class="hljs-number">255</span>,<span class="hljs-number">0</span>),<span class="hljs-number">2</span>)

cv2.imshow(<span class="hljs-string">&#x27;line&#x27;</span>, img)
cv2.waitKey(<span class="hljs-number">0</span>)
cv2.destroyAllWindows()</code></pre>
<p><a href="WEBRESOURCE3d58de354780265626a38c2cc7664f32" title="image.png" class="gallery-item"><img src="WEBRESOURCE3d58de354780265626a38c2cc7664f32" srcset="/img/loading.gif" alt="image.png"></a></p>
<h2 id="轮廓的性质"><a href="#轮廓的性质" class="headerlink" title="轮廓的性质"></a>轮廓的性质</h2><h3 id="长宽比"><a href="#长宽比" class="headerlink" title="长宽比"></a>长宽比</h3><p>边界矩形的宽高比。</p>
<pre><code class="hljs python"><span class="hljs-keyword">import</span> cv2
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np

img = cv2.imread(<span class="hljs-string">&#x27;lightning.png&#x27;</span>,<span class="hljs-number">0</span>)

ret,thresh = cv2.threshold(img,<span class="hljs-number">127</span>,<span class="hljs-number">255</span>,<span class="hljs-number">0</span>)
contours,hierarchy = cv2.findContours(thresh, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>)
cnt = contours[<span class="hljs-number">0</span>]

x,y,w,h = cv2.boundingRect(cnt)
aspect_ratio = <span class="hljs-built_in">float</span>(w)/h
print(aspect_ratio)</code></pre>
<p><a href="WEBRESOURCEac045e4efdc7c14b437113a586b826de" title="image.png" class="gallery-item"><img src="WEBRESOURCEac045e4efdc7c14b437113a586b826de" srcset="/img/loading.gif" alt="image.png"></a></p>
<h3 id="Extent"><a href="#Extent" class="headerlink" title="Extent"></a>Extent</h3><p>轮廓面积与边界矩形面积的比。</p>
<pre><code class="hljs math">Extent &#x3D; \frac&#123;Object Area&#125;&#123;Bounding Rectangle Area&#125;</code></pre>
<pre><code class="hljs python"><span class="hljs-keyword">import</span> cv2
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np

img = cv2.imread(<span class="hljs-string">&#x27;lightning.png&#x27;</span>,<span class="hljs-number">0</span>)

ret,thresh = cv2.threshold(img,<span class="hljs-number">127</span>,<span class="hljs-number">255</span>,<span class="hljs-number">0</span>)
contours,hierarchy = cv2.findContours(thresh, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>)
cnt = contours[<span class="hljs-number">0</span>]

area = cv2.contourArea(cnt)
x,y,w,h = cv2.boundingRect(cnt)
rect_area = w*h
extent = <span class="hljs-built_in">float</span>(area)/rect_area

print(extent)</code></pre>
<p><a href="WEBRESOURCEa1043dc4b0db301d228b74f9aaad4267" title="image.png" class="gallery-item"><img src="WEBRESOURCEa1043dc4b0db301d228b74f9aaad4267" srcset="/img/loading.gif" alt="image.png"></a></p>
<h3 id="Solidity"><a href="#Solidity" class="headerlink" title="Solidity"></a>Solidity</h3><p>轮廓面积与凸包面积的比。</p>
<pre><code class="hljs math">Solidity &#x3D; \frac&#123;Contour Area&#125;&#123;ConvexHull Area&#125;</code></pre>
<pre><code class="hljs python"><span class="hljs-keyword">import</span> cv2
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np

img = cv2.imread(<span class="hljs-string">&#x27;lightning.png&#x27;</span>,<span class="hljs-number">0</span>)

ret,thresh = cv2.threshold(img,<span class="hljs-number">127</span>,<span class="hljs-number">255</span>,<span class="hljs-number">0</span>)
contours,hierarchy = cv2.findContours(thresh, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>)
cnt = contours[<span class="hljs-number">0</span>]

area = cv2.contourArea(cnt)
hull = cv2.convexHull(cnt)
hull_area = cv2.contourArea(hull)
solidity = <span class="hljs-built_in">float</span>(area)/hull_area

print(solidity)</code></pre>
<p><a href="WEBRESOURCE19632f2c170caea6527610b59acef7e9" title="image.png" class="gallery-item"><img src="WEBRESOURCE19632f2c170caea6527610b59acef7e9" srcset="/img/loading.gif" alt="image.png"></a></p>
<h3 id="Equivalent-Diameter"><a href="#Equivalent-Diameter" class="headerlink" title="Equivalent Diameter"></a>Equivalent Diameter</h3><pre><code class="hljs math">Equivalent Diameter &#x3D; \frac&#123;\sqrt&#123;4\times Contour Area&#125;&#125;&#123;\pi&#125;</code></pre>
<pre><code class="hljs python"><span class="hljs-keyword">import</span> cv2
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np

img = cv2.imread(<span class="hljs-string">&#x27;lightning.png&#x27;</span>,<span class="hljs-number">0</span>)

ret,thresh = cv2.threshold(img,<span class="hljs-number">127</span>,<span class="hljs-number">255</span>,<span class="hljs-number">0</span>)
contours,hierarchy = cv2.findContours(thresh, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>)
cnt = contours[<span class="hljs-number">0</span>]

area = cv2.contourArea(cnt)
equi_diameter = np.sqrt(<span class="hljs-number">4</span>*area/np.pi)

print(equi_diameter)</code></pre>
<p><a href="WEBRESOURCE93e75bd6330166f15a29c532bad84a81" title="image.png" class="gallery-item"><img src="WEBRESOURCE93e75bd6330166f15a29c532bad84a81" srcset="/img/loading.gif" alt="image.png"></a></p>
<h3 id="方向"><a href="#方向" class="headerlink" title="方向"></a>方向</h3><p>也就是对象的方向，下面的方法<code>cv2.fitEllipse()</code>还会返回长轴和短轴的长度:</p>
<pre><code class="hljs python"><span class="hljs-keyword">import</span> cv2
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np

img = cv2.imread(<span class="hljs-string">&#x27;lightning.png&#x27;</span>,<span class="hljs-number">0</span>)

ret,thresh = cv2.threshold(img,<span class="hljs-number">127</span>,<span class="hljs-number">255</span>,<span class="hljs-number">0</span>)
contours,hierarchy = cv2.findContours(thresh, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>)
cnt = contours[<span class="hljs-number">0</span>]

(x,y),(MA,ma),angle = cv2.fitEllipse(cnt)

print(<span class="hljs-built_in">str</span>(x) + <span class="hljs-string">&quot;, &quot;</span> + <span class="hljs-built_in">str</span>(y) + <span class="hljs-string">&#x27;, &#x27;</span> + <span class="hljs-built_in">str</span>(angle))
print(<span class="hljs-built_in">str</span>(MA) + <span class="hljs-string">&#x27;, &#x27;</span> + <span class="hljs-built_in">str</span>(ma))</code></pre>
<p><a href="WEBRESOURCE341e267661de5f836fe7cb9339eb1624" title="image.png" class="gallery-item"><img src="WEBRESOURCE341e267661de5f836fe7cb9339eb1624" srcset="/img/loading.gif" alt="image.png"></a></p>
<h3 id="极点"><a href="#极点" class="headerlink" title="极点"></a>极点</h3><p>一个对象最上面，最下面，最左边，最右边的点。</p>
<p><a href="WEBRESOURCE739119999303a817f10c3b168626d3ef" title="image.png" class="gallery-item"><img src="WEBRESOURCE739119999303a817f10c3b168626d3ef" srcset="/img/loading.gif" alt="image.png"></a><br>&lt;!–hexoPostRenderEscape:<pre><code class="hljs python"><span class="hljs-keyword">import</span> cv2<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np</p>
<p>img = cv2.imread(<span class="hljs-string">&#x27;lightning.png&#x27;</span>,<span class="hljs-number">0</span>)</p>
<p>ret,thresh = cv2.threshold(img,<span class="hljs-number">127</span>,<span class="hljs-number">255</span>,<span class="hljs-number">0</span>)<br>contours,hierarchy = cv2.findContours(thresh, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>)<br>cnt = contours[<span class="hljs-number">0</span>]</p>
<p>leftmost = <span class="hljs-built_in">tuple</span>(cnt[cnt[:,:,<span class="hljs-number">0</span>].argmin()][<span class="hljs-number">0</span>])<br>rightmost = <span class="hljs-built_in">tuple</span>(cnt[cnt[:,:,<span class="hljs-number">0</span>].argmax()][<span class="hljs-number">0</span>])<br>topmost = <span class="hljs-built_in">tuple</span>(cnt[cnt[:,:,<span class="hljs-number">1</span>].argmin()][<span class="hljs-number">0</span>])<br>bottommost = <span class="hljs-built_in">tuple</span>(cnt[cnt[:,:,<span class="hljs-number">1</span>].argmax()][<span class="hljs-number">0</span>])</p>
<p>print(leftmost)<br>print(rightmost)<br>print(topmost)<br>print(bottommost)</code></pre>:hexoPostRenderEscape–&gt;<br><a href="WEBRESOURCE7823e8a650b8b22752b15854fa3ae0ce" title="image.png" class="gallery-item"><img src="WEBRESOURCE7823e8a650b8b22752b15854fa3ae0ce" srcset="/img/loading.gif" alt="image.png"></a></p>
<h1 id="轮廓的层次结构"><a href="#轮廓的层次结构" class="headerlink" title="轮廓的层次结构"></a>轮廓的层次结构</h1></div><script src="https://cdn.jsdelivr.net/lightgallery.js/1.0.1/js/lightgallery.min.js"></script><script>if (typeof lightGallery !== 'undefined') {
        var options = {
            selector: '.gallery-item'
        };
        lightGallery(document.getElementsByClassName('.article-gallery')[0], options);
        }</script>
            </div>
            <hr>
            <div>
              <div class="post-metas mb-3">
                
                  <div class="post-meta mr-3">
                    <i class="iconfont icon-category"></i>
                    
                      <a class="hover-with-bg" href="/categories/Python/">Python</a>
                    
                  </div>
                
                
                  <div class="post-meta">
                    <i class="iconfont icon-tags"></i>
                    
                      <a class="hover-with-bg" href="/tags/opencv-python/">opencv-python</a>
                    
                  </div>
                
              </div>
              
                <p class="note note-warning">本博客所有文章除特别声明外，均采用 <a target="_blank" href="https://creativecommons.org/licenses/by-sa/4.0/deed.zh" rel="nofollow noopener noopener">CC BY-SA 4.0 协议</a> ，转载请注明出处！</p>
              
              
                <div class="post-prevnext row">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2020/03/15/OpenCV%E6%A0%B8%E5%BF%83%E6%93%8D%E4%BD%9C/">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">OpenCV核心操作</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2018/12/07/C++%E5%87%BD%E6%95%B0/">
                        <span class="hidden-mobile">C++函数</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>
    
      <div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn">
        <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div class="toc-body" id="toc-body"></div>
</div>

      </div>
    
  </div>
</div>

<!-- Custom -->


    

    
      <a id="scroll-top-button" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
    

    
  </main>

  <footer class="text-center mt-5 py-3">
  <div class="footer-content">
     <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
  </div>
  

  

  
</footer>

<!-- SCRIPTS -->

  <script  src="https://cdn.staticfile.org/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://cdn.staticfile.org/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":200})
    NProgress.start()
    document.addEventListener('DOMContentLoaded', function() {
      window.NProgress && window.NProgress.inc();
    })
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://cdn.staticfile.org/jquery/3.5.1/jquery.min.js" ></script>
<script  src="https://cdn.staticfile.org/twitter-bootstrap/4.5.3/js/bootstrap.min.js" ></script>
<script  src="/js/debouncer.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>

<!-- Plugins -->


  
    <script  src="/js/lazyload.js" ></script>
  



  



  <script  src="https://cdn.staticfile.org/tocbot/4.12.0/tocbot.min.js" ></script>



  <script  src="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.js" ></script>



  <script  src="https://cdn.staticfile.org/anchor-js/4.3.0/anchor.min.js" ></script>



  <script defer src="https://cdn.staticfile.org/clipboard.js/2.0.6/clipboard.min.js" ></script>





  <script  src="https://cdn.staticfile.org/typed.js/2.0.11/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var title = document.getElementById('subtitle').title;
      
      typing(title)
      
    })(window, document);
  </script>



  <script  src="/js/local-search.js" ></script>
  <script>
    (function () {
      var path = "/local-search.xml";
      var inputArea = document.querySelector("#local-search-input");
      inputArea.onclick = function () {
        searchFunc(path, 'local-search-input', 'local-search-result');
        this.onclick = null
      }
    })()
  </script>















<!-- 主题的启动项 保持在最底部 -->
<script  src="/js/boot.js" ></script>



<script src="/live2dw/lib/L2Dwidget.min.js?0c58a1486de42ac6cc1c59c7d98ae887"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>
</html>
